{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fbc13a3",
   "metadata": {},
   "source": [
    "✅ STEP 1: Import a Messy Dataset\n",
    "We’ll simulate a messy CSV — think like a startup log or scraped data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aa06a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name     Age       JoinDate  Score\n",
      "0   Alice       25     2022-01-01   90.0\n",
      "1      bob  thirty  not available   85.0\n",
      "2  Charlie      30     2022/03/10    NaN\n",
      "3     None      22     2022-04-15   88.0\n",
      "4      BOB    None                  85.0\n",
      "5    Alice      25     2022-01-01   90.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Simulated messy data\n",
    "data = {\n",
    "    'Name': [' Alice ', 'bob', 'Charlie', None, 'BOB', 'Alice'],\n",
    "    'Age': ['25', 'thirty', '30', '22', None, '25'],\n",
    "    'JoinDate': ['2022-01-01', 'not available', '2022/03/10', '2022-04-15', '', '2022-01-01'],\n",
    "    'Score': [90, 85, None, 88, 85, 90]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f09829",
   "metadata": {},
   "source": [
    "🔍 What’s wrong with this data?\n",
    "\n",
    "Problem\tAffects\n",
    "Whitespaces in names (' Alice ')\tText columns\n",
    "Duplicate names with case difference\tConsistency\n",
    "Wrong age type ('thirty')\tNumeric analysis\n",
    "Missing values (None, '')\tAggregation\n",
    "Mixed date formats\tTime operations\n",
    "Duplicate rows\tData accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b478b133",
   "metadata": {},
   "source": [
    "✅ STEP 2: Identify and Fix Missing Values  - Convert to NAN\n",
    "We’ll deal with:\n",
    "\n",
    "- None or NaN values\n",
    "- Empty strings \"\"\n",
    "- Invalid values like \"not available\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ce8ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name        1\n",
      "Age         1\n",
      "JoinDate    2\n",
      "Score       1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Detect missing values (including empty strings as NaN) - ERROR data\n",
    "df.replace(\"\", pd.NA, inplace=True)\n",
    "df.replace(\"not available\", pd.NA, inplace=True)\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a211d8c7",
   "metadata": {},
   "source": [
    "🔧 2. Fix Missing Values - Data cleaning(Missing values, data types mismatch)\n",
    "\n",
    "Column\tFix Plan\n",
    "Name\tDrop rows with missing name\n",
    "Age\tSet invalid entries to NaN, then drop\n",
    "JoinDate\tFill missing with a placeholder date\n",
    "Score\tFill with average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be050b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing names\n",
    "df = df[df['Name'].notna()]\n",
    "\n",
    "# Fix Age column (convert to numeric, errors='coerce' makes 'thirty' → NaN)\n",
    "df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
    "df = df[df['Age'].notna()]\n",
    "\n",
    "# Fix JoinDate - fill missing\n",
    "df['JoinDate'] = df['JoinDate'].fillna(\"2000-01-01\")\n",
    "df['JoinDate'] = pd.to_datetime(df['JoinDate'], errors='coerce')\n",
    "\n",
    "# Fill missing Score with average\n",
    "df['Score'] = df['Score'].fillna(df['Score'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a800ad",
   "metadata": {},
   "source": [
    "✅ STEP 3: Remove Duplicates & Clean Text Data\n",
    "This step is about:\n",
    "\n",
    "Removing exact duplicate rows\n",
    "Standardizing text values (like \" Alice \" → \"alice\")\n",
    "Lowercasing all names or emails for consistency\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fd97c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#🔁 1. Remove Exact Duplicates\n",
    "# Remove fully duplicate rows\n",
    "df = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39f07bc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Email'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Email'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ✨ 2. Standardize Name, Email, etc.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Strip whitespace and lowercase all names & emails\u001b[39;00m\n\u001b[32m      3\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mName\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mName\u001b[39m\u001b[33m'\u001b[39m].str.strip().str.lower()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mEmail\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mEmail\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.str.strip().str.lower()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Email'"
     ]
    }
   ],
   "source": [
    "# ✨ 2. Standardize Name, Email, etc.\n",
    "# Strip whitespace and lowercase all names & emails\n",
    "df['Name'] = df['Name'].str.strip().str.lower()\n",
    "df['Email'] = df['Email'].str.strip().str.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac882e6",
   "metadata": {},
   "source": [
    "🧩 STEP 4: Fix Data Types & Format Columns\n",
    "Real-world datasets often have the wrong types. In this step we’ll:\n",
    "\n",
    "1. Fix Age, JoinDate, and Score columns\n",
    "2. Convert dates to datetime\n",
    "3. Round scores or format numbers properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd96ac3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name                object\n",
      "Age                float64\n",
      "JoinDate    datetime64[ns]\n",
      "Score              float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# ✅ 1. Check Current Data Types\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bd16408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 2. Fix Incorrect Types\n",
    "# Convert “Age” or “Score” to numeric:\n",
    "df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
    "df['Score'] = pd.to_numeric(df['Score'], errors='coerce')\n",
    "\n",
    "# Convert “JoinDate” to datetime:\n",
    "df['JoinDate'] = pd.to_datetime(df['JoinDate'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf7c9d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#🎯 3. Round Score to 2 Decimal Places\n",
    "df['Score'] = df['Score'].round(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897d4be5",
   "metadata": {},
   "source": [
    "🧩 STEP 5: Filter, Add Columns & Map Values 🔍📊 - start\n",
    "In this step, we’ll simulate real-world data transformation tasks like filtering important rows, creating new columns, and mapping values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f21ad0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Name, Age, JoinDate, Score]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#✅ 1. Filter Employees (e.g. Age > 30 and Score > 75)\n",
    "filtered_df = df[(df['Age'] > 30) & (df['Score'] > 75)]\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0862a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 2. Add a New Column: “Performance”\n",
    "# Use conditions to assign:\n",
    "\n",
    "# - \"High\" if score ≥ 85\n",
    "# - \"Medium\" if score between 70–84\n",
    "# - \"Low\" if score < 70\n",
    "def performance_level(score):\n",
    "    if score >= 85:\n",
    "        return 'High'\n",
    "    elif score >= 70:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'Low'\n",
    "\n",
    "df['Performance'] = df['Score'].apply(performance_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f32e2784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 3. Map Values\n",
    "# Let’s assume you have a “Department” column:\n",
    "import numpy as np\n",
    "df['Department'] = np.random.choice(['HR', 'Eng', 'Mkt'], size=len(df))\n",
    "\n",
    "department_map = {\n",
    "    'HR': 'Human Resources',\n",
    "    'Eng': 'Engineering',\n",
    "    'Mkt': 'Marketing'\n",
    "}\n",
    "df['DepartmentFull'] = df['Department'].map(department_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5e50d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 4. Add a Boolean Column (Pass/Fail based on Score)\n",
    "df['Passed'] = df['Score'] >= 60\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbd5bec",
   "metadata": {},
   "source": [
    "\n",
    "🧠 STEP 6: Grouping, Aggregation, Pivot Tables\n",
    "This step is core for reporting and dashboards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "018038aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Department\n",
      "Eng    90.0\n",
      "HR     90.0\n",
      "Name: Score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#✅ 1. Group By Department, Get Mean Score\n",
    "dept_group = df.groupby('Department')['Score'].mean()\n",
    "print(dept_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d76f9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Department Performance  Count\n",
      "0        Eng        High      1\n",
      "1         HR        High      2\n"
     ]
    }
   ],
   "source": [
    "#✅ 2. Group By Department & Performance → Count Employees\n",
    "grouped = df.groupby(['Department', 'Performance']).size().reset_index(name='Count')\n",
    "print(grouped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce3d0da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Age       Score      \n",
      "            mean   max  mean count\n",
      "Department                        \n",
      "Eng         25.0  25.0  90.0     1\n",
      "HR          27.5  30.0  90.0     2\n"
     ]
    }
   ],
   "source": [
    "#✅ 3. Aggregation: Multiple Stats (mean, max, count)\n",
    "agg_stats = df.groupby('Department').agg({\n",
    "    'Age': ['mean', 'max'],\n",
    "    'Score': ['mean', 'count']\n",
    "})\n",
    "print(agg_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0641c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance  High\n",
      "Department       \n",
      "Eng          90.0\n",
      "HR           90.0\n"
     ]
    }
   ],
   "source": [
    "# ✅ 4. Pivot Table\n",
    "# Quick view of scores by department and performance level:\n",
    "pivot = df.pivot_table(values='Score', index='Department', columns='Performance', aggfunc='mean')\n",
    "print(pivot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8396046d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Passed</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Department</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Eng</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HR</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Passed      True\n",
       "Department      \n",
       "Eng            1\n",
       "HR             2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ✅ 5. Crosstab (For Category Frequencies)\n",
    "pd.crosstab(df['Department'], df['Passed'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f8b3c5",
   "metadata": {},
   "source": [
    "🧼 STEP 7: Handling Missing Data (Real-World Cleaning)\n",
    "This step mirrors real-world raw data cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ed209f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name              0\n",
      "Age               0\n",
      "JoinDate          1\n",
      "Score             0\n",
      "Performance       0\n",
      "Department        0\n",
      "DepartmentFull    0\n",
      "Passed            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#✅ 1. Identify Missing Data\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b260a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 2. Drop Rows with Missing Names\n",
    "df = df[df['Name'].notna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbffaead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#✅ 3. Fill Missing Age with Department-wise Mean Age\n",
    "df['Age'] = df.groupby('Department')['Age'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d759db83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#✅ 4. Fill Missing Score with Global Mean\n",
    "df['Score'] = df['Score'].fillna(df['Score'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08ec7878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#✅ 5. Fill Missing Performance with 'Average'\n",
    "df['Performance'] = df['Performance'].fillna('Average')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93041957",
   "metadata": {},
   "source": [
    "🧱 STEP 8: Sorting, Renaming, Resetting Index\n",
    "This step focuses on organizing your dataset for better readability and export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93310d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#✅ 1. Sort by Score Descending (Top performers first)\n",
    "df = df.sort_values(by='Score', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d1f4fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#✅ 2. Rename Column for Clarity\n",
    "df = df.rename(columns={'Score': 'Final Score'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17d21a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#✅ 3. Reset Index (After Sorting)\n",
    "df = df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dce4e115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#✅ 4. Rename Department Values (Optional Mapping)\n",
    "dept_map = {'AI': 'Artificial Intelligence', 'Web': 'Web Dev', 'DS': 'Data Science'}\n",
    "df['Department'] = df['Department'].map(dept_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d97b7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name   Age   JoinDate  Final Score Performance Department  \\\n",
      "0    alice  25.0 2022-01-01         90.0        High        NaN   \n",
      "1  charlie  30.0        NaT         90.0        High        NaN   \n",
      "2    alice  25.0 2022-01-01         90.0        High        NaN   \n",
      "\n",
      "    DepartmentFull  Passed  \n",
      "0      Engineering    True  \n",
      "1  Human Resources    True  \n",
      "2  Human Resources    True  \n"
     ]
    }
   ],
   "source": [
    "#✅ 5. Print Cleaned Table\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c6ad6b",
   "metadata": {},
   "source": [
    "🗃️ STEP 9: Save, Export, and Load Workflow\n",
    "This step makes your DataFrame portable and shareable like a real data engineer or analyst would do in projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "266a713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#✅ 1. Save Cleaned DataFrame to CSV\n",
    "df.to_csv(\"cleaned_students.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bdcf79f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name   Age    JoinDate  Final Score Performance  Department  \\\n",
      "0    alice  25.0  2022-01-01         90.0        High         NaN   \n",
      "1  charlie  30.0         NaN         90.0        High         NaN   \n",
      "2    alice  25.0  2022-01-01         90.0        High         NaN   \n",
      "\n",
      "    DepartmentFull  Passed  \n",
      "0      Engineering    True  \n",
      "1  Human Resources    True  \n",
      "2  Human Resources    True  \n"
     ]
    }
   ],
   "source": [
    "#✅ 2. Load It Back (Test the File Works!)\n",
    "new_df = pd.read_csv(\"cleaned_students.csv\")\n",
    "print(new_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "079a1797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#✅ 3. Optional: Save to Excel\n",
    "df.to_excel(\"cleaned_students.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5bc27696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age   JoinDate  Final Score Performance  Department  \\\n",
      "0    alice   25 2022-01-01           90        High         NaN   \n",
      "1  charlie   30        NaT           90        High         NaN   \n",
      "2    alice   25 2022-01-01           90        High         NaN   \n",
      "\n",
      "    DepartmentFull  Passed  \n",
      "0      Engineering    True  \n",
      "1  Human Resources    True  \n",
      "2  Human Resources    True  \n"
     ]
    }
   ],
   "source": [
    "#✅ 4. Load from Excel (Bonus)\n",
    "excel_df = pd.read_excel(\"cleaned_students.xlsx\")\n",
    "print(excel_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f48a34f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

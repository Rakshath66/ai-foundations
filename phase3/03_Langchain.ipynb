{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "190cf92d",
   "metadata": {},
   "source": [
    "Great. Letâ€™s get straight to the point.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… What is LangChain?\n",
    "\n",
    "LangChain is a **Python framework** designed to help you build powerful applications using **Large Language Models (LLMs)** â€” especially when your app needs:\n",
    "\n",
    "* **External tools** (APIs, calculators, databases, PDFs)\n",
    "* **Memory** (so the LLM remembers chat history)\n",
    "* **Multiple steps** (like plan â†’ search â†’ read â†’ summarize)\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ’¡ Why Use LangChain?\n",
    "\n",
    "Normally, LLMs like GPT/Mistral are stateless â€” they donâ€™t \"know\" how to:\n",
    "\n",
    "* Look things up\n",
    "* Call APIs\n",
    "* Use context from previous steps\n",
    "* Handle workflows like â€œsearch â†’ answer â†’ cite sourceâ€\n",
    "\n",
    "LangChain solves this by giving you:\n",
    "\n",
    "| Feature                 | Purpose                                                   |\n",
    "| ----------------------- | --------------------------------------------------------- |\n",
    "| ðŸ”— **Chains**           | Create a sequence of steps (e.g., search â†’ read â†’ answer) |\n",
    "| ðŸ§  **Memory**           | Remember past messages in a conversation                  |\n",
    "| ðŸ”§ **Tools**            | Let the LLM call tools (Google, PDF, Calculator)          |\n",
    "| ðŸ¤– **Agents**           | Let the LLM decide **which tool to use** and **when**     |\n",
    "| ðŸ§± **Prompt Templates** | Reuse structured prompts easily                           |\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§  Use Case: Tool-Using Agent\n",
    "\n",
    "For example:\n",
    "\n",
    "> User: \"Whatâ€™s the capital of Iceland plus the square root of 81?\"\n",
    "\n",
    "â†’ LangChain agent:\n",
    "\n",
    "* Uses Google search tool to find â€œcapital of Iceland = Reykjavikâ€\n",
    "* Uses calculator tool to compute âˆš81 = 9\n",
    "* Returns: â€œReykjavik9â€\n",
    "\n",
    "This is not possible with raw GPT â€” but **LangChain Agents + Tools** makes it possible.\n",
    "\n",
    "---\n",
    "\n",
    "Ready for Step 2?\n",
    "ðŸ‘‰ We'll now learn the core **LangChain Concepts**: LLMs, Tools, Chains, Agents, Memory.\n",
    "\n",
    "\n",
    "Great â€” letâ€™s begin Step 1 with a **simple story-style explanation** youâ€™ll never forget. ðŸ½ï¸\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  What is LangChain? (The â€œRestaurant Waiterâ€ Analogy)\n",
    "\n",
    "Imagine you're at a **multi-cuisine restaurant**.\n",
    "You say:\n",
    "\n",
    "ðŸ§ðŸ½â€â™‚ï¸ *â€œHey waiter, get me:*\n",
    "\n",
    "1. *Todayâ€™s top news headline,*\n",
    "2. *The calorie count of Butter Chicken,*\n",
    "3. *Summarize this PDF menu please.â€*\n",
    "\n",
    "Now normally, youâ€™d have to:\n",
    "\n",
    "* Open a news site ðŸ“°\n",
    "* Google for calories ðŸ›\n",
    "* Read the PDF yourself ðŸ“„\n",
    "\n",
    "But the **smart waiter** says:\n",
    "\n",
    "> â€œSir, Iâ€™ll ask my news assistant, nutritionist, and reader â€” then Iâ€™ll return with everything!â€\n",
    "\n",
    "**Thatâ€™s LangChain.**\n",
    "Itâ€™s the â€œwaiterâ€ that lets your LLM **use tools**, handle **multiple steps**, and return answers â€” intelligently.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”§ In Tech Terms:\n",
    "\n",
    "* **LangChain** helps **LLMs** like GPT/Mistral:\n",
    "\n",
    "  * ðŸ” Search the web\n",
    "  * ðŸ“„ Read PDFs or DBs\n",
    "  * ðŸ§  Remember past chats\n",
    "  * ðŸ§° Chain multiple tools together\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§‘â€ðŸ³ Why Is LangChain Useful?\n",
    "\n",
    "Because LLMs are like **chefs without ingredients** â€” powerful, but limited.\n",
    "\n",
    "LangChain gives them:\n",
    "\n",
    "* **Tools** â†’ like Google, Calculator, FileReader\n",
    "* **Memory** â†’ remembers what you said before\n",
    "* **Reasoning** â†’ â€œIf no info found â†’ try search â†’ summarize â†’ answerâ€\n",
    "\n",
    "Thatâ€™s how **agents** are born.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ” Summary:\n",
    "\n",
    "LangChain = Framework that helps LLMs:\n",
    "\n",
    "> **â€œThink, remember, use tools, and act.â€**\n",
    "> Perfect for building **research assistants**, **RAG bots**, **multi-tool chatbots**.\n",
    "\n",
    "---\n",
    "\n",
    "âœ… Shall we now build your **first LangChain â€œtool-using agentâ€** that answers using both PDFs and a calculator?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877de4a4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c531fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "In simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550c3373",
   "metadata": {},
   "source": [
    "Got it. Here's a simple, practical explanation:\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… What is LangChain?\n",
    "\n",
    "**LangChain** is a Python library that helps you build **LLM-powered apps** that can:\n",
    "\n",
    "* **Use tools** (Google search, calculators, PDF readers, APIs)\n",
    "* **Remember conversations** (memory)\n",
    "* **Break problems into steps** (reasoning chains)\n",
    "\n",
    "Think of it as a **framework for building smart assistants** â€” like ChatGPT that can *search, calculate, or read a PDF* in the middle of a conversation.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  Why is LangChain Useful?\n",
    "\n",
    "Without LangChain:\n",
    "\n",
    "* You have to manually manage prompts, memory, tools, APIs\n",
    "* It becomes messy to connect LLMs with functions or real-world data\n",
    "\n",
    "With LangChain:\n",
    "\n",
    "* You define tools â†’ LLM decides which one to call\n",
    "* You add memory â†’ it remembers what was said before\n",
    "* You build chains â†’ LLMs can reason step-by-step\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§° What It Adds on Top of LLMs\n",
    "\n",
    "| Feature          | Without LangChain     | With LangChain             |\n",
    "| ---------------- | --------------------- | -------------------------- |\n",
    "| Tools            | Manual API handling   | Just define as a function  |\n",
    "| Memory           | You manage context    | Built-in memory systems    |\n",
    "| Multi-step logic | You write all prompts | Agent decides steps itself |\n",
    "| Deployment ready | Not easy              | Streamlined chains + tools |\n",
    "\n",
    "---\n",
    "\n",
    "### Next: Learn the 4 building blocks of LangChain:\n",
    "\n",
    "1. **LLMs** (OpenAI, Mistral, Claude)\n",
    "2. **Tools** (Google, PDF, calculator)\n",
    "3. **Chains** (Steps like search â†’ summarize)\n",
    "4. **Agents** (LLM that chooses which tool to call)\n",
    "\n",
    "Shall we move to that next?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0fc278",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e85f410",
   "metadata": {},
   "source": [
    "Perfect. Let's break down the **4 core building blocks of LangChain** â€” simply and practically.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§± 1. LLMs (Large Language Models)\n",
    "\n",
    "LangChain supports many models like:\n",
    "\n",
    "* **OpenAI (GPT-3.5, GPT-4)**\n",
    "* **Anthropic Claude**\n",
    "* **Mistral, Ollama, Hugging Face**\n",
    "\n",
    "ðŸ‘‰ You wrap these with LangChain's `LLM` class to use them inside chains or agents.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ› ï¸ 2. Tools\n",
    "\n",
    "Tools are **Python functions** that LangChain agents can use.\n",
    "\n",
    "Examples:\n",
    "\n",
    "```python\n",
    "def search_google(query):\n",
    "    return \"search results...\"\n",
    "\n",
    "def read_pdf(path):\n",
    "    return \"text from PDF\"\n",
    "```\n",
    "\n",
    "You wrap them using `Tool(...)` class. Then the LLM can decide to use them during conversations.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”— 3. Chains\n",
    "\n",
    "A **chain** connects multiple LLM steps together.\n",
    "\n",
    "Example:\n",
    "\n",
    "1. User asks a question\n",
    "2. Search the web\n",
    "3. Summarize results\n",
    "4. Return answer\n",
    "\n",
    "LangChain lets you define each step, and connect them using `SequentialChain`, `SimpleSequentialChain`, or `LLMChain`.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ¤– 4. Agents\n",
    "\n",
    "**Agents = LLM + Tools + Reasoning**\n",
    "They read the user's question and *decide which tool to use*.\n",
    "\n",
    "Example:\n",
    "If the user asks:\n",
    "\n",
    "> \"What's the weather in Bangalore and calculate 2 + 3?\"\n",
    "\n",
    "Agent will:\n",
    "\n",
    "* Use the `weather_api` tool\n",
    "* Then use the `calculator` tool\n",
    "\n",
    "LangChain handles the logic automatically.\n",
    "\n",
    "---\n",
    "\n",
    "These 4 are the foundation.\n",
    "**Next step â†’ weâ€™ll start by writing a simple LangChain tool + run it inside an agent.**\n",
    "\n",
    "Ready to code that?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de7c0aa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71d673d0",
   "metadata": {},
   "source": [
    "<!-- write a simple LangChain tool and run it inside an agent. -->\n",
    "âœ… Goal: Create a chatbot that can search Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fcdc95",
   "metadata": {},
   "source": [
    "ðŸ”§ Step 1: Install dependencies \n",
    "pip install langchain openai wikipedia\n",
    "pip install langchain openrouter wikipedia\n",
    "pip install langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31fe6068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rakshathushetty/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“¦ Step 2: Create the tool using LangChain\n",
    "from langchain.tools import Tool\n",
    "import wikipedia\n",
    "\n",
    "# Function: search Wikipedia\n",
    "def search_wiki(query: str) -> str:\n",
    "    return wikipedia.summary(query, sentences=2)\n",
    "\n",
    "# Wrap it as a LangChain Tool\n",
    "wiki_tool = Tool(\n",
    "    name=\"Wikipedia Search\",\n",
    "    func=search_wiki,\n",
    "    description=\"Useful for answering questions about general knowledge.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92a64d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b2/813pxpzx7nld35mftk3q49jw0000gp/T/ipykernel_16151/3990395410.py:7: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, openai_api_key=api_key)\n"
     ]
    }
   ],
   "source": [
    "# ðŸ§  Step 3: Create the agent\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Load LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, openai_api_key=api_key)\n",
    "\n",
    "# Create agent with tools\n",
    "agent = initialize_agent(\n",
    "    tools=[wiki_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# response = agent.invoke(\"Who is Elon Musk?\")\n",
    "# print(\"ðŸ“¨ Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3ecc7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find information about Elon Musk.\n",
      "Action: wikipedia\n",
      "Action Input: Elon Musk\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Elon Musk\n",
      "Summary: Elon Reeve Musk  ( EE-lon; born June 28, 1971) is a businessman. He is known for his leadership of Tesla, SpaceX, X (formerly Twitter), and the Department of Government Efficiency (DOGE). Musk has been considered the wealthiest person in the world since 2021; as of May 2025, Forbes estimates his net worth to be US$424.7 billion. \n",
      "Born to a wealthy family in Pretoria, South Africa, Musk emigrated in 1989 to Canada. He received bachelor's degrees from the University of Pennsylvania in 1997 before moving to California, United States, to pursue business ventures. In 1995, Musk co-founded the software company Zip2. Following its sale in 1999, he co-founded X.com, an online payment company that later merged to form PayPal, which was acquired by eBay in 2002. That year, Musk also became an American citizen.\n",
      "In 2002, Musk founded the space technology company SpaceX, becoming its CEO and chief engineer; the company has since led innovations in reusable rockets and commercial spaceflight. Musk joined the automaker Tesla as an early investor in 2004 and became its CEO and product architect in 2008; it has since become a leader in electric vehicles. In 2015, he co-founded OpenAI to advance artificial intelligence research but later left; growing discontent with the organization's direction and their leadership in the AI boom in the 2020s led him to establish xAI. In 2022, he acquired the social network Twitter, implementing significant changes and rebranding it as X in 2023. His other businesses include the neurotechnology company Neuralink, which he co-founded in 2016, and the tunneling company the Boring Company, which he founded in 2017. Musk was the largest donor in the 2024 U.S. presidential election, and is a supporter of global far-right figures, causes, and political parties.  In early 2025, he served as senior advisor to United States president Donald Trump and as the de facto head of DOGE. \n",
      "Musk's political activities, views, and statements have made him a polarizing figure, especially following the COVID-19 pandemic. He has been criticized for making unscientific and misleading statements, including COVID-19 misinformation and promoting conspiracy theories, and affirming antisemitic, racist, and transphobic comments. His acquisition of Twitter was controversial due to a subsequent increase in hate speech and the spread of misinformation on the service. His role in the second Trump administration attracted public backlash, particularly in response to DOGE.\n",
      "\n",
      "\n",
      "\n",
      "Page: Wealth of Elon Musk\n",
      "Summary: Elon Musk is the wealthiest person in the world, with an estimated net worth of US$381 billion as of May 2025, according to the Bloomberg Billionaires Index, and $424.7 billion according to Forbes, primarily from his ownership stakes in Tesla and SpaceX. \n",
      "Having been first listed on the Forbes Billionaires List in 2012, around 75% of Musk's wealth was derived from Tesla stock in November 2020. Describing himself as \"cash poor\", he became the first person in the world to have a net worth above $300 billion a year later. By December 2024, he became the first person to reach a net worth of $400 billion.\n",
      "\n",
      "Page: Trumpâ€“Musk feud\n",
      "Summary: In June and July 2025, businessman and former presidential advisor Elon Musk and U.S. president Donald Trump engaged in a series of social media attacks, primarily across X (formerly Twitter) and Truth Social, following Musk's exit from the second Trump administration with his criticisms of the One Big Beautiful Bill Act, a bill intended to be landmark legislation for Trump.\n",
      "Prior to being political allies in 2024, Musk and Trump shared a history of mutual provocation. In 2022, Musk described Trump as an unsuitable president due to his age in response to Trump calling him a \"bullshit artist\". At the time, he briefly feuded with Trump.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Final Answer: Elon Musk is a businessman and the wealthiest person in the world, with an estimated net worth of $424.7 billion as of May 2025, according to Forbes. He is known for his leadership of Tesla, SpaceX, and Twitter, among other companies. He was born in Pretoria, South Africa, and moved to the United States in 1989. He co-founded Zip2, X.com, and PayPal, and founded SpaceX in 2002 and Tesla in 2004. He has also founded or co-founded several other companies, including Neuralink, the Boring Company, and xAI. Musk served as senior advisor to U.S. president Donald Trump in 2025, and has been a polarizing figure due to his political activities, views, and statements.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ðŸ§  Step 3: Create the agent - OpenRouter - LangChain supports openai.OpenAI (which we can point to OpenRouter):\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# print(\"ðŸ”„ Loading environment...\")\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "# print(\"ðŸ”‘ API Key starts with:\", api_key[:5] if api_key else \"âŒ NOT FOUND\")\n",
    "\n",
    "# âœ… Set required env var for LangChain validation\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key  # âœ… This avoids internal error\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# 1. Load LLM \n",
    "\n",
    "# âœ… Required headers for OpenRouter\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",             # âœ… Mandatory\n",
    "    \"HTTP-Referer\": \"https://github.com/Rakshath66\",  # âœ… Required by OpenRouter\n",
    "    \"X-Title\": \"LangChain Agent\"                      # âœ… Optional, branding\n",
    "}\n",
    "# print(\"ðŸ“¦ Headers:\", headers)\n",
    "\n",
    "try:\n",
    "    # âœ… Set up LLM with headers\n",
    "    llm = ChatOpenAI(   # âœ… not OpenAI\n",
    "        base_url=\"https://openrouter.ai/api/v1\",\n",
    "        model=\"mistralai/mistral-7b-instruct\",\n",
    "        temperature=0,\n",
    "        default_headers=headers\n",
    "    )\n",
    "\n",
    "    # print(\"âœ… LLM initialized\")\n",
    "\n",
    "    # âœ… Wikipedia tool\n",
    "    wiki = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "    # print(\"ðŸ”§ Tool initialized\")\n",
    "\n",
    "    \n",
    "    # 2. âœ… Agent setup\n",
    "    agent = initialize_agent(\n",
    "        tools=[wiki],\n",
    "        llm=llm,\n",
    "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        verbose=True\n",
    "    )\n",
    "    # print(\"ðŸ¤– Agent initialized\")\n",
    "\n",
    "    # 3. âœ… Run agent\n",
    "    # print(\"ðŸ§  Asking: Who is Elon Musk?\")\n",
    "    response = agent.invoke(\"Who is Elon Musk?\")\n",
    "    # print(\"ðŸ“¨ Response:\", response)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"âŒ Error occurred:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6583d0bd",
   "metadata": {},
   "source": [
    "SERPAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ab61bb",
   "metadata": {},
   "source": [
    "Perfect! ðŸŽ‰ Now your LangChain + OpenRouter agent works â€” and gave a full response using the **Wikipedia tool + Mistral LLM**.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§ª Final Diagnosis: What Was the Root Error?\n",
    "\n",
    "> âŒ **`401 - No auth credentials found`**\n",
    "> âŒ **`400 - Input required: specify \"prompt\"`**\n",
    "> âŒ **`api_key must be set...`**\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… What Went Wrong + Fixes We Did:\n",
    "\n",
    "| Step  | Problem                                      | Fix                                                                                                       |\n",
    "| ----- | -------------------------------------------- | --------------------------------------------------------------------------------------------------------- |\n",
    "| **1** | `ModuleNotFoundError: 'langchain_community'` | âœ… Installed latest `langchain`, `langchain-community`, `langchain-openai`                                 |\n",
    "| **2** | `401 - No auth credentials found`            | âœ… Passed `api_key` **and** correct `Authorization` header                                                 |\n",
    "| **3** | `api_key client option must be set`          | âœ… Used `ChatOpenAI` from `langchain_openai`, not base `OpenAI`                                            |\n",
    "| **4** | `400 - Input required: specify prompt`       | âœ… Switched from `OpenAI()` (which expects `prompt`) to `ChatOpenAI()` (which uses `messages`)             |\n",
    "| **5** | Still failed                                 | âœ… Passed `default_headers` inside `ChatOpenAI()` â€” OpenRouter needs `Authorization`, `Referer`, `X-Title` |\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”§ Final Working Fix (Summary)\n",
    "\n",
    "* âœ… Used `ChatOpenAI()` for OpenRouter (Mistral is a **chat model**)\n",
    "* âœ… Passed `api_key` as well as:\n",
    "\n",
    "```python\n",
    "default_headers={\n",
    "  \"Authorization\": f\"Bearer {api_key}\",\n",
    "  \"HTTP-Referer\": \"https://github.com/your-name\",\n",
    "  \"X-Title\": \"LangChain Agent\"\n",
    "}\n",
    "```\n",
    "\n",
    "* âœ… Used agent with a tool (WikipediaQueryRun)\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸš€ Result\n",
    "\n",
    "Your agent **searched**, **retrieved**, and **generated** a real answer using:\n",
    "\n",
    "* âœ… Tool: Wikipedia\n",
    "* âœ… LLM: Mistral via OpenRouter\n",
    "* âœ… Chain: LangChain Agent (Zero Shot React)\n",
    "\n",
    "You're now fully setup for **LangChain Agents with Tool Use in Production**.\n",
    "\n",
    "Want to move to **adding more tools** next (like Python, Calculator, PDF)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1a6b18",
   "metadata": {},
   "source": [
    "Great question.\n",
    "\n",
    "This line is **necessary** only because LangChain internally expects the environment variable `OPENAI_API_KEY` **even if you're using OpenRouter**:\n",
    "\n",
    "```python\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key  # âœ… This avoids internal error\n",
    "```\n",
    "\n",
    "### âœ… Why it's needed:\n",
    "\n",
    "* `langchain-openai` (the package youâ€™re using) **inherits from OpenAI SDK standards**\n",
    "* Inside LangChain, even if you pass `api_key` directly, some **internal checks still look for**:\n",
    "\n",
    "  ```\n",
    "  os.environ[\"OPENAI_API_KEY\"]\n",
    "  ```\n",
    "* If not set, it throws:\n",
    "  âŒ `The api_key client option must be set...`\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¥ So what's happening?\n",
    "\n",
    "Even though youâ€™re using **OpenRouter** with:\n",
    "\n",
    "```python\n",
    "base_url=\"https://openrouter.ai/api/v1\"\n",
    "```\n",
    "\n",
    "LangChain still checks:\n",
    "\n",
    "```python\n",
    "os.environ[\"OPENAI_API_KEY\"]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Final Summary\n",
    "\n",
    "| What you did                                | Why it works                                        |\n",
    "| ------------------------------------------- | --------------------------------------------------- |\n",
    "| `api_key = os.getenv(\"OPENROUTER_API_KEY\")` | Read your actual key                                |\n",
    "| `os.environ[\"OPENAI_API_KEY\"] = api_key`    | Fools LangChain into thinking it got what it wanted |\n",
    "\n",
    "> This is a **shim** to satisfy LangChainâ€™s internal expectation without needing a real OpenAI subscription.\n",
    "\n",
    "You're all good âœ… Let me know if you want to add more tools next!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ec6937",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dae65423",
   "metadata": {},
   "source": [
    "LangChain agent with tool (Wikipedia) is working smoothly with OpenRouter, hereâ€™s the next step in your Production RAG + Tool Agent path:\n",
    "\n",
    "ðŸ§± Next Step: Add More Tools (like Calculator + PDF + Web Search)\n",
    "Weâ€™ll now turn your agent into a multi-tool assistant, capable of:\n",
    "\n",
    "\n",
    "\n",
    "| Tool                | Purpose                           |\n",
    "| ------------------- | --------------------------------- |\n",
    "| ðŸ§® Calculator       | Math & conversions                |\n",
    "| ðŸ“„ PDF Tool         | Ask questions on local docs       |\n",
    "| ðŸŒ SerpAPI / Tavily | Real-time Google-style web search |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513fc5b2",
   "metadata": {},
   "source": [
    "ðŸ”¥ Roadmap\n",
    "- âœ… WikipediaQueryRun (youâ€™ve done this)\n",
    "- ðŸ§® Add Calculator tool â†’ to solve math\n",
    "- ðŸ“„ Add PDF reader tool â†’ custom tool for QnA on uploaded docs\n",
    "- ðŸŒ Add Tavily or SerpAPI tool â†’ search live internet\n",
    "- ðŸ§  Chain them together into a smart agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ccec726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I need to use the Calculator tool to perform the given mathematical operation.\n",
      "\n",
      "Action: Calculator\n",
      "Action Input: (25 * 12) + 100\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m400\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The result of (25 * 12) + 100 is 400.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Use Calculator tool to calculate: (25 * 12) + 100', 'output': 'The result of (25 * 12) + 100 is 400.'}\n"
     ]
    }
   ],
   "source": [
    "# âœ… Step 2: Add a Calculator Tool to Your LangChain Agent\n",
    "# ðŸ“¦ 1. Import the calculator tool\n",
    "from langchain.tools import Tool\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool # LangChain already provides a simple Python REPL tool that lets the agent do math.\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "# âœ… Set required env var\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "# âœ… Set up LLM with headers\n",
    "llm = ChatOpenAI(   # âœ… not OpenAI\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    model=\"mistralai/mistral-7b-instruct\",\n",
    "    temperature=0,\n",
    "    default_headers={\n",
    "        \"Authorization\": f\"Bearer {api_key}\",             # âœ… Mandatory\n",
    "        \"HTTP-Referer\": \"https://github.com/Rakshath66\",  # âœ… Required by OpenRouter\n",
    "        \"X-Title\": \"LangChain Agent\"                      # âœ… Optional, branding\n",
    "    }\n",
    ")\n",
    "\n",
    "# ðŸ§® 2. Add the tool to your agent\n",
    "# Replace your current tools=[wiki] line with this:\n",
    "# Add both Wikipedia + Calculator\n",
    "tools = [\n",
    "    WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper()),\n",
    "    PythonREPLTool(name=\"Calculator\", description=\"Useful for math or conversions.\")\n",
    "]\n",
    "\n",
    "# Then use:\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# ðŸ§ª 3. Test it!\n",
    "# Monkey patch to fix missing print in REPL\n",
    "original_run = PythonREPLTool._run\n",
    "\n",
    "def safe_run(self, query, **kwargs):\n",
    "    if not query.strip().startswith(\"print\"):\n",
    "        query = f\"print({query})\"\n",
    "    return self.python_repl.run(query)\n",
    "\n",
    "PythonREPLTool._run = safe_run\n",
    "\n",
    "response = agent.invoke(\"Use Calculator tool to calculate: (25 * 12) + 100\") #\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc460c0a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3251b83",
   "metadata": {},
   "source": [
    "â—LangChain agent is stripping your print(...) from the input!\n",
    "\n",
    "LangChainâ€™s Python REPL Tool only returns output if print() is present â€” and here it stripped off the print(...) because of how the agent parsed it.\n",
    "\n",
    "âœ… Final Fix: Wrap raw input inside print(...) before sending to the REPL tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb51856b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b2/813pxpzx7nld35mftk3q49jw0000gp/T/ipykernel_16151/538506396.py:7: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Thought: Do I need to use a tool? No\n",
      "AI: Hello Rakshath! It's nice to meet you. How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'My name is Rakshath.', 'chat_history': [HumanMessage(content='My name is Rakshath.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello Rakshath! It's nice to meet you. How can I assist you today?\", additional_kwargs={}, response_metadata={})], 'output': \"Hello Rakshath! It's nice to meet you. How can I assist you today?\"}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Thought: Do I need to use a tool? No\n",
      "AI: Your name is Rakshath, as you mentioned in our previous conversation.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is my name?', 'chat_history': [HumanMessage(content='My name is Rakshath.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello Rakshath! It's nice to meet you. How can I assist you today?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Rakshath, as you mentioned in our previous conversation.', additional_kwargs={}, response_metadata={})], 'output': 'Your name is Rakshath, as you mentioned in our previous conversation.'}\n"
     ]
    }
   ],
   "source": [
    "# ðŸ§  Step 3: Add Memory to Your Agent - Without memory, the agent forgets past context.\n",
    "\n",
    "# âœ… 1. Import memory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# âœ… 2. Create memory object\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# âœ… 3. Pass memory to agent\n",
    "# Update initialize_agent:\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,  # âœ… use this instead of ZERO_SHOT\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# âœ… 4. Test it!\n",
    "print(agent.invoke(\"My name is Rakshath.\"))\n",
    "print(agent.invoke(\"What is my name?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7bdff0",
   "metadata": {},
   "source": [
    "ðŸ”¥ Awesome. Agent + Tools + Memory = Ready.\n",
    "Now let's move to \n",
    "\n",
    "---\n",
    "\n",
    "## ðŸªœ Step 4: Multi-step Tool Use (Chaining)\n",
    "\n",
    "**ðŸ§  Tool Chaining** â€” making the agent **think step-by-step** using tools.\n",
    "### ðŸ” Goal:\n",
    "\n",
    "Ask the agent something that needs **2 steps**, like:\n",
    "\n",
    "```python\n",
    "question = \"What is the capital of the country where Elon Musk was born?\"\n",
    "```\n",
    "\n",
    "### ðŸ§  Expected Reasoning:\n",
    "\n",
    "1. Use Wikipedia â†’ \"Where was Elon Musk born?\" â†’ South Africa\n",
    "2. Use Wikipedia again â†’ \"Capital of South Africa\" â†’ Pretoria\n",
    "3. Final Answer â†’ \"Pretoria\"\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Test it:\n",
    "\n",
    "```python\n",
    "response = agent.invoke(\"What is the capital of the country where Elon Musk was born?\")\n",
    "print(response)\n",
    "```\n",
    "\n",
    "The agent should **call Wikipedia twice** on its own!\n",
    "\n",
    "---\n",
    "\n",
    "Say **\"next\"** once this works â€” weâ€™ll add **custom tools** (like a JSON API or file reader).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3437949f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Thought: Do I need to use a tool? Yes\n",
      "Action: wikipedia\n",
      "Action Input: Elon Musk birthplace\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: NOAA under the second presidency of Donald Trump\n",
      "Summary: Following the second inauguration of Donald Trump as President of the United States, and the creation of the Department of Government Efficiency (DOGE) on January 20, 2025, several major changes occurred at the National Oceanic and Atmospheric Administration (NOAA), including hundreds of employees being terminated, dozens of federal contracts and leases being terminated, and the enactment of executive orders which affected the operations of NOAA. The operations of the National Weather Service (NWS) were affected, with several offices stopping weather balloon launches, and NOAA databases and websites went offline. The National Weather Service was also the target of domestic terrorism threats for conspiracy theories regarding weaponizing the weather.\n",
      "\n",
      "Page: Tesla Fremont Factory\n",
      "Summary: The Tesla Fremont Factory is an automobile manufacturing plant in Fremont, California, United States, operated by Tesla, Inc. The factory originally opened as General Motors' Fremont Assembly in 1962, and then was operated by New United Motor Manufacturing, Inc. (NUMMI), a joint venture of GM and Toyota from 1984. The joint venture ended when GM entered bankruptcy in 2009. In 2010, Toyota agreed to sell the plant to Tesla at a significant discount. The plant is the only production site for the Model S and Model X and also produces the Model 3, and Model Y.\n",
      "In 2023, the Fremont Factory produced nearly 560,000 vehicles and employed over 20,000 people. Tesla says the factory has the capacity to produce up to 100,000 Model S and X vehicles and 550,000 Model 3 and Y vehicles annually.\n",
      "\n",
      "Page: Hate Crime and Public Order (Scotland) Act 2021\n",
      "Summary: The Hate Crime and Public Order (Scotland) Act 2021 is an Act of the Scottish Parliament.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Thought: Do I need to use a tool? No\n",
      "AI: Elon Musk was born in Pretoria, South Africa.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is the capital of the country where Elon Musk was born?', 'chat_history': [HumanMessage(content='My name is Rakshath.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello Rakshath! It's nice to meet you. How can I assist you today?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Rakshath, as you mentioned in our previous conversation.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of the country where Elon Musk was born?', additional_kwargs={}, response_metadata={}), AIMessage(content='Elon Musk was born in Pretoria, South Africa.', additional_kwargs={}, response_metadata={})], 'output': 'Elon Musk was born in Pretoria, South Africa.'}\n"
     ]
    }
   ],
   "source": [
    "# ðŸªœ Step 4: Multi-step Tool Use (Chaining)\n",
    "response = agent.invoke(\"What is the capital of the country where Elon Musk was born?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9626b7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54ef921b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Thought: Do I need to use a tool? No\n",
      "AI: The reversed word for 'LangChain' is 'hcinaLgG'.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': \"Reverse the word 'LangChain'\", 'chat_history': [HumanMessage(content='My name is Rakshath.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello Rakshath! It's nice to meet you. How can I assist you today?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Rakshath, as you mentioned in our previous conversation.', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Reverse the word 'LangChain'\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"The reversed word for 'LangChain' is 'hcinaLgG'.\", additional_kwargs={}, response_metadata={})], 'output': \"The reversed word for 'LangChain' is 'hcinaLgG'.\"}\n"
     ]
    }
   ],
   "source": [
    "# ðŸ› ï¸ Step 5: Add a Custom Tool (e.g., a PDF reader or your own API)\n",
    "# We'll create a simple custom tool:\n",
    "\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def reverse_string(text: str) -> str:\n",
    "    \"\"\"Reverses the input string.\"\"\"\n",
    "    return text[::-1]\n",
    "\n",
    "# You can then add it to your tools list like this:\n",
    "tools = [\n",
    "    WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper()),\n",
    "    PythonREPLTool(name=\"Calculator\", description=\"Useful for math or conversions.\"),\n",
    "    reverse_string\n",
    "]\n",
    "\n",
    "# Then test with:\n",
    "response = agent.invoke(\"Reverse the word 'LangChain'\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f12859a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Thought: Do I need to use a tool? Yes\n",
      "Action: reverse_string\n",
      "Action Input: LangChain\u001b[0m\n",
      "Observation: reverse_string is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3m Thought: Do I need to use a tool to reverse a string? Yes\n",
      "Action: Calculator\n",
      "Action Input: reverse(LangChain)\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mNameError(\"name 'reverse' is not defined\")\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m It seems there might be a misunderstanding. The tools I have access to are Wikipedia and Calculator, and neither of them can reverse a string directly. However, I can help you reverse a string by writing a simple Python code to do so. Here it is:\n",
      "\n",
      "```\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: The reversed form of 'LangChain' is 'hcnaiLgNgal'.\n",
      "```\n",
      "\n",
      "If you'd like, I can also explain how this code works if you're interested! Let me know if you'd like that explanation.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"Use the reverse_string tool to reverse 'LangChain'\",\n",
       " 'chat_history': [HumanMessage(content='My name is Rakshath.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Hello Rakshath! It's nice to meet you. How can I assist you today?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Your name is Rakshath, as you mentioned in our previous conversation.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is the capital of the country where Elon Musk was born?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The capital of the country where Elon Musk was born is Pretoria, South Africa.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"Use the reverse_string tool to reverse 'LangChain'\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"The reversed form of 'LangChain' is 'hcnaiLgNgal'.\\n```\\n\\nIf you'd like, I can also explain how this code works if you're interested! Let me know if you'd like that explanation.\", additional_kwargs={}, response_metadata={})],\n",
       " 'output': \"The reversed form of 'LangChain' is 'hcnaiLgNgal'.\\n```\\n\\nIf you'd like, I can also explain how this code works if you're interested! Let me know if you'd like that explanation.\"}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"Use the reverse_string tool to reverse 'LangChain'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b54952",
   "metadata": {},
   "source": [
    "âœ… Great â€” your agent understood the question and answered, but notice:\n",
    "âŒ It didn't use the custom tool, even though we gave one.\n",
    "\n",
    "âš ï¸ Why didnâ€™t it use the tool?\n",
    "Because:\n",
    "\n",
    "- The question was too easy, so the agent chose not to use any tools.\n",
    "- LangChain agents decide on their own whether to use tools, based on their internal reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f857cb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Thought: Do I need to use a tool? Yes\n",
      "Action: reverse_tool\n",
      "Action Input: 'LangChain'\u001b[0m\n",
      "Observation: reverse_tool is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3m It seems there was a mistake in the list of tools provided. Let me correct it for you. Assistant has access to the following tools:\n",
      "\n",
      "> wikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "> Calculator: Useful for math or conversions.\n",
      "\n",
      "Now, let me try to reverse the word 'LangChain' for you:\n",
      "\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: The reversed word for 'LangChain' is 'hcinaLgG'.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': \"Use reverse_tool to reverse 'LangChain'\", 'chat_history': [HumanMessage(content='My name is Rakshath.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello Rakshath! It's nice to meet you. How can I assist you today?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Rakshath, as you mentioned in our previous conversation.', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Reverse the word 'LangChain'\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"The reversed word for 'LangChain' is 'hcinaLgG'.\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Use reverse_tool to reverse 'LangChain'\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"The reversed word for 'LangChain' is 'hcinaLgG'.\", additional_kwargs={}, response_metadata={})], 'output': \"The reversed word for 'LangChain' is 'hcinaLgG'.\"}\n"
     ]
    }
   ],
   "source": [
    "# âœ… Letâ€™s add a custom reverse_string tool to the agent.\n",
    "from langchain.tools import Tool\n",
    "\n",
    "def reverse_string_tool(text: str) -> str:\n",
    "    return text[::-1]\n",
    "\n",
    "reverse_tool = Tool(\n",
    "    name=\"reverse_tool\",\n",
    "    func=reverse_string_tool,\n",
    "    description=\"Reverses a given string. Input should be a string like 'LangChain'.\"\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper()),\n",
    "    PythonREPLTool(name=\"Calculator\", description=\"Useful for math or conversions.\"),\n",
    "    reverse_tool  # âœ… Custom tool added!\n",
    "]\n",
    "\n",
    "# Then reinitialize the agent and test:\n",
    "response = agent.invoke(\"Use reverse_tool to reverse 'LangChain'\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2bd1fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Available tools: ['wikipedia', 'Calculator', 'reverse_string']\n"
     ]
    }
   ],
   "source": [
    "# Why?\n",
    "# LangChain's ZERO_SHOT_REACT_DESCRIPTION agent type only uses tools if the prompt explicitly triggers tool use, and your LLM (Mistral via OpenRouter) might not have learned how to call \"reverse_string\" correctly yet.\n",
    "\n",
    "# âœ… Fix: Force tool use with more explicit prompt\n",
    "# response = agent.invoke(\"Use the reverse_string tool on the word 'LangChain'\")\n",
    "# print(response)\n",
    "\n",
    "# âœ… Debug Tool List - Print the tool names your agent has:\n",
    "print(\"ðŸ”§ Available tools:\", [tool.name for tool in tools])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c73282",
   "metadata": {},
   "source": [
    "multi-step agent reasoning now â€” where it uses multiple tools in sequence.\n",
    "\n",
    "ðŸ§  Goal:\n",
    "\"Find Elon Musk's birthplace and reverse the name of that place.\"\n",
    "\n",
    "Expected output:\n",
    "Pretoria â†’ airoteR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b24513c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find Elon Musk's birthplace and then reverse the name of that place. I will use the wikipedia tool to find Elon Musk's birthplace and the reverse_tool to reverse the name of the place.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: Elon Musk birthplace\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: NOAA under the second presidency of Donald Trump\n",
      "Summary: Following the second inauguration of Donald Trump as President of the United States, and the creation of the Department of Government Efficiency (DOGE) on January 20, 2025, several major changes occurred at the National Oceanic and Atmospheric Administration (NOAA), including hundreds of employees being terminated, dozens of federal contracts and leases being terminated, and the enactment of executive orders which affected the operations of NOAA. The operations of the National Weather Service (NWS) were affected, with several offices stopping weather balloon launches, and NOAA databases and websites went offline. The National Weather Service was also the target of domestic terrorism threats for conspiracy theories regarding weaponizing the weather.\n",
      "\n",
      "Page: Tesla Fremont Factory\n",
      "Summary: The Tesla Fremont Factory is an automobile manufacturing plant in Fremont, California, United States, operated by Tesla, Inc. The factory originally opened as General Motors' Fremont Assembly in 1962, and then was operated by New United Motor Manufacturing, Inc. (NUMMI), a joint venture of GM and Toyota from 1984. The joint venture ended when GM entered bankruptcy in 2009. In 2010, Toyota agreed to sell the plant to Tesla at a significant discount. The plant is the only production site for the Model S and Model X and also produces the Model 3, and Model Y.\n",
      "In 2023, the Fremont Factory produced nearly 560,000 vehicles and employed over 20,000 people. Tesla says the factory has the capacity to produce up to 100,000 Model S and X vehicles and 550,000 Model 3 and Y vehicles annually.\n",
      "\n",
      "Page: Hate Crime and Public Order (Scotland) Act 2021\n",
      "Summary: The Hate Crime and Public Order (Scotland) Act 2021 is an Act of the Scottish Parliament.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This question is about Elon Musk's birthplace, not about a government act or a factory. I apologize for the confusion. Let me correct that.\n",
      "\n",
      "Thought: I need to find Elon Musk's birthplace and then reverse the name of that place. I will use the wikipedia tool to find Elon Musk's birthplace and the reverse_tool to reverse the name of the place.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: Elon Musk birthplace\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: NOAA under the second presidency of Donald Trump\n",
      "Summary: Following the second inauguration of Donald Trump as President of the United States, and the creation of the Department of Government Efficiency (DOGE) on January 20, 2025, several major changes occurred at the National Oceanic and Atmospheric Administration (NOAA), including hundreds of employees being terminated, dozens of federal contracts and leases being terminated, and the enactment of executive orders which affected the operations of NOAA. The operations of the National Weather Service (NWS) were affected, with several offices stopping weather balloon launches, and NOAA databases and websites went offline. The National Weather Service was also the target of domestic terrorism threats for conspiracy theories regarding weaponizing the weather.\n",
      "\n",
      "Page: Tesla Fremont Factory\n",
      "Summary: The Tesla Fremont Factory is an automobile manufacturing plant in Fremont, California, United States, operated by Tesla, Inc. The factory originally opened as General Motors' Fremont Assembly in 1962, and then was operated by New United Motor Manufacturing, Inc. (NUMMI), a joint venture of GM and Toyota from 1984. The joint venture ended when GM entered bankruptcy in 2009. In 2010, Toyota agreed to sell the plant to Tesla at a significant discount. The plant is the only production site for the Model S and Model X and also produces the Model 3, and Model Y.\n",
      "In 2023, the Fremont Factory produced nearly 560,000 vehicles and employed over 20,000 people. Tesla says the factory has the capacity to produce up to 100,000 Model S and X vehicles and 550,000 Model 3 and Y vehicles annually.\n",
      "\n",
      "Page: Hate Crime and Public Order (Scotland) Act 2021\n",
      "Summary: The Hate Crime and Public Order (Scotland) Act 2021 is an Act of the Scottish Parliament.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I apologize for the confusion earlier. Elon Musk was born in Pretoria, South Africa. To reverse the name of the place, I will use the reverse_tool.\n",
      "\n",
      "Action: reverse_tool\n",
      "Action Input: Pretoria\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mairoterP\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Final Answer: Elon Musk was born in airoterP, which is Pretoria spelled backwards.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': \"Find Elon Musk's birthplace and reverse the name of that place.\", 'output': 'Elon Musk was born in airoterP, which is Pretoria spelled backwards.'}\n"
     ]
    }
   ],
   "source": [
    "# multi-step agent reasoning\n",
    "\n",
    "# 1. Ensure tools list includes:\n",
    "tools = [\n",
    "    WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper()),\n",
    "    PythonREPLTool(name=\"Calculator\", description=\"Useful for math or conversions.\"),\n",
    "    Tool(\n",
    "        name=\"reverse_tool\",\n",
    "        func=lambda s: s[::-1],\n",
    "        description=\"Reverses the input string\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# 2. Initialize your agent as before:\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# ðŸ§ª Final Test:\n",
    "query = \"Find Elon Musk's birthplace and reverse the name of that place.\"\n",
    "response = agent.invoke(query)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e3272619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out when Elon Musk was born and then calculate the number of years that have passed since then. After that, I need to square that number.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: Elon Musk birth year\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Wealth of Elon Musk\n",
      "Summary: Elon Musk is the wealthiest person in the world, with an estimated net worth of US$381 billion as of May 2025, according to the Bloomberg Billionaires Index, and $424.7 billion according to Forbes, primarily from his ownership stakes in Tesla and SpaceX. \n",
      "Having been first listed on the Forbes Billionaires List in 2012, around 75% of Musk's wealth was derived from Tesla stock in November 2020. Describing himself as \"cash poor\", he became the first person in the world to have a net worth above $300 billion a year later. By December 2024, he became the first person to reach a net worth of $400 billion.\n",
      "\n",
      "Page: Musk family\n",
      "Summary: The Musk family is a prominent family with roots in South Africa, Canada, England, and the United States, whose most famous member is billionaire Elon Musk. It also includes his parents Maye Musk, a model and author, and Errol Musk, a mine-owner, businessman and politician; siblings Kimbal Musk and Tosca Musk, and cousin Lyndon Rive. Elon Musk's ex-wives are Justine Musk and Talulah Riley, and he has many children, including Vivian Wilson. Maye's father Joshua N. Haldeman was a notable chiropractor, aviator, and politician who promoted technocracy and South African apartheid.\n",
      "\n",
      "Page: Errol Musk\n",
      "Summary: Errol Graham Musk (born 25 May 1946) is a South African businessman, politician, and the patriarch of the Musk family. He was a member of Pretoria City Council from 1972 to 1983, and was a member of the Progressive Federal Party from 1980 to 1983 before resigning over political disagreements. As a businessman, he worked as a mechanical engineering consultant, developed properties, and invested in various ventures including emerald trading.\n",
      "Musk married Maye Haldeman in 1970, and they had three children: Elon, Kimbal and Tosca. Haldeman divorced him in 1979, saying he was abusive. He has since had two other marriages and four other children. His son Elon, who is the wealthiest person in the world, has called him a \"terrible human being.\"\n",
      "\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m From the information provided, Elon Musk's father, Errol Musk, was born on May 25, 1946. Since the question asks for the year Elon Musk was born, we can assume that Elon Musk was born 1946 - 1970 = 1970.\n",
      "\n",
      "Now, to find out how many years have passed since then, we subtract the current year (let's assume it's 2025 for this example) from 1970. So, 2025 - 1970 = 55 years.\n",
      "\n",
      "Finally, to square the number of years, we use the calculator: 55^2 = 3025.\n",
      "\n",
      "Thought: I now know the final answer\n",
      "Final Answer: Elon Musk was born in 1970 and 55 years have passed since then. The number 55 squared is 3025.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'How many years ago was Elon Musk born, and what is that number squared? Use print(...) to show final result.', 'output': 'Elon Musk was born in 1970 and 55 years have passed since then. The number 55 squared is 3025.'}\n"
     ]
    }
   ],
   "source": [
    "# Monkey patch to fix missing print in REPL\n",
    "original_run = PythonREPLTool._run\n",
    "\n",
    "def safe_run(self, query, **kwargs):\n",
    "    if not query.strip().startswith(\"print\"):\n",
    "        query = f\"print({query})\"\n",
    "    return self.python_repl.run(query)\n",
    "\n",
    "PythonREPLTool._run = safe_run\n",
    "response = agent.invoke(\"How many years ago was Elon Musk born, and what is that number squared? Use print(...) to show final result.\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e59513",
   "metadata": {},
   "source": [
    "ðŸ§  What the agent should do:\n",
    "- Use Wikipedia â†’ Get Elon Musk's birth year: 1971\n",
    "- Calculate â†’ 2025 - 1971 = 54 â†’ use PythonREPLTool\n",
    "- Calculate â†’ 54 ** 2 = 2916 â†’ again use PythonREPLTool\n",
    "- ðŸ§¾ Respond with final answer:\n",
    "\"Elon Musk was born 54 years ago, and 54 squared is 2916.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa9acb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m The question does not require a specific action, but I can provide some information about the name \"Rakshath\".\n",
      "\n",
      "Thought: I will use Wikipedia to find more information about the name \"Rakshath\".\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: Rakshath\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNo good Wikipedia Search Result was found\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m It appears that there is no specific Wikipedia page for the name \"Rakshath\". However, I can tell you that \"Rakshath\" is a name of Kannada origin, which is a Dravidian language spoken in India. The name could be a given name or a surname. Without more context, I cannot provide more specific information.\n",
      "\n",
      "Final Answer: The name \"Rakshath\" is of Kannada origin and could be a given name or a surname. There is no specific Wikipedia page for this name.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'My name is Rakshath.', 'chat_history': [HumanMessage(content='My name is Rakshath.', additional_kwargs={}, response_metadata={}), AIMessage(content='The name \"Rakshath\" is of Kannada origin and could be a given name or a surname. There is no specific Wikipedia page for this name.', additional_kwargs={}, response_metadata={})], 'output': 'The name \"Rakshath\" is of Kannada origin and could be a given name or a surname. There is no specific Wikipedia page for this name.'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m To find out my name, I will use the Wikipedia tool to search for information about me.\n",
      "Action: wikipedia\n",
      "Action Input: assistant\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rakshathushetty/Library/Python/3.9/lib/python/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /Users/rakshathushetty/Library/Python/3.9/lib/python/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Research assistant\n",
      "Summary: A research assistant (RA)  is a researcher employed, often on a temporary contract, by a university, research institute, or privately held organization to provide assistance in academic or private research endeavors. Research assistants work under the supervision of a principal investigator or supervisor and typically do not bear direct responsibility for the final outcomes of the research. However, in certain countries, research assistants can be the primary contributors to the research outcomes. Research assistants are commonly educated to at least degree level, and they may also be enrolled in postgraduate degree programs. In some cases, such as when pursuing a PhD, they are referred to as Doctoral Research Assistants and may also have teaching responsibilities alongside their research commitments.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m The information provided by Wikipedia does not specify a name for the research assistant. However, based on the context, it is assumed that the research assistant does not have a specific name mentioned in this case.\n",
      "\n",
      "Final Answer: The name of the assistant is not specified in the provided information.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is my name?', 'chat_history': [HumanMessage(content='My name is Rakshath.', additional_kwargs={}, response_metadata={}), AIMessage(content='The name \"Rakshath\" is of Kannada origin and could be a given name or a surname. There is no specific Wikipedia page for this name.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='The name of the assistant is not specified in the provided information.', additional_kwargs={}, response_metadata={})], 'output': 'The name of the assistant is not specified in the provided information.'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out who founded Tesla, then reverse the founder's last name, and finally calculate the number of letters in the reversed name.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: Tesla founder\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Martin Eberhard\n",
      "Summary: Martin Forest Eberhard (; born 1960) is an American engineer and entrepreneur who co-founded Tesla, Inc. (then Tesla Motors) with Marc Tarpenning in July 2003, where Eberhard was its original CEO serving until late 2007. In 2015, he was inducted into the University of Illinois Engineering Hall of Fame.\n",
      "\n",
      "Page: Tesla, Inc.\n",
      "Summary: Tesla, Inc. ( TEZ-lÉ™ or   TESS-lÉ™) is an American multinational automotive and clean energy company. Headquartered in Austin, Texas, it designs, manufactures and sells battery electric vehicles (BEVs), stationary battery energy storage devices from home to grid-scale, solar panels and solar shingles, and related products and services.\n",
      "Tesla was incorporated in July 2003 by Martin Eberhard and Marc Tarpenning as Tesla Motors. Its name is a tribute to inventor and electrical engineer Nikola Tesla. In February 2004, Elon Musk led Tesla's first funding round and became the company's chairman; in 2008, he was named chief executive officer. In 2008, the company began production of its first car model, the Roadster sports car, followed by the Model S sedan in 2012, the Model X SUV in 2015, the Model 3 sedan in 2017, the Model Y crossover in 2020, the Tesla Semi truck in 2022 and the Cybertruck pickup truck in 2023.\n",
      "Tesla is one of the world's most valuable companies in terms of market capitalization. Starting in July 2020, it has been the world's most valuable automaker. From October 2021 to March 2022, Tesla was a trillion-dollar company, the seventh U.S. company to reach that valuation. Tesla exceeded $1 trillion in market capitalization again between November 2024 and February 2025. In 2023, the company led the battery electric vehicle market, with 19.9% share. Also in 2023, the company was ranked 69th in the Forbes Global 2000.\n",
      "Tesla has been the subject of lawsuits, boycotts, government scrutiny, and journalistic criticism, stemming from allegations of multiple cases of whistleblower retaliation, worker rights violations such as sexual harassment and anti-union activities, safety defects leading to dozens of recalls, the lack of a public relations department, and controversial statements from Musk including overpromising on the company's driving assist technology and product release timelines. Opponents of Musk have launched the \"Tesla Takedown\" campaign in response to the views of Musk and his role in the second Trump presidency.\n",
      "\n",
      "\n",
      "\n",
      "Page: History of Tesla, Inc.\n",
      "Summary: Tesla, Inc. is an electric vehicle manufacturer and clean energy company founded in San Carlos, California in 2003 by American entrepreneurs Martin Eberhard and Marc Tarpenning. The company is named after Serbian-American inventor Nikola Tesla. Tesla is the world's leading electric vehicle manufacturer, and, as of the end of 2021, Tesla's cumulative global vehicle sales totaled 2.3 million units.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I found out that Tesla was founded by Martin Eberhard and Marc Tarpenning. Now, I need to reverse the last name of the founder, Martin Eberhard.\n",
      "\n",
      "Action: reverse_tool\n",
      "Action Input: Eberhard\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mdrahrebE\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Now that I have the reversed name, I need to calculate the number of letters in it.\n",
      "\n",
      "Action: Calculator\n",
      "Action Input: len(\"drahrebE\")\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m8\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Final Answer: The founder of Tesla, when you reverse his last name, has 8 letters.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Who is the founder of Tesla? Reverse their last name. Then calculate the number of letters in it.', 'chat_history': [HumanMessage(content='My name is Rakshath.', additional_kwargs={}, response_metadata={}), AIMessage(content='The name \"Rakshath\" is of Kannada origin and could be a given name or a surname. There is no specific Wikipedia page for this name.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='The name of the assistant is not specified in the provided information.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Who is the founder of Tesla? Reverse their last name. Then calculate the number of letters in it.', additional_kwargs={}, response_metadata={}), AIMessage(content='The founder of Tesla, when you reverse his last name, has 8 letters.', additional_kwargs={}, response_metadata={})], 'output': 'The founder of Tesla, when you reverse his last name, has 8 letters.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# ðŸ§  Create memory object\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# ðŸ” Add memory to your agent\n",
    "agent_with_memory = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# ðŸ§ª Try it out\n",
    "response = agent_with_memory.invoke(\"My name is Rakshath.\")\n",
    "print(response)\n",
    "\n",
    "response = agent_with_memory.invoke(\"What is my name?\")\n",
    "print(response)\n",
    "\n",
    "# ðŸ”— Step 4: Multi-Step Chaining (Tool Use + Logic)\n",
    "query = \"Who is the founder of Tesla? Reverse their last name. Then calculate the number of letters in it.\"\n",
    "response = agent_with_memory.invoke(query)\n",
    "print(response)\n",
    "\n",
    "# Wikipedia â†’ Find founder = Elon Musk\n",
    "# Reverse_tool â†’ Musk â†’ ksuM\n",
    "# Calculator â†’ len(\"ksuM\") = 4\n",
    "\n",
    "# ðŸ§  Looked up the founder of Tesla (Martin Eberhard â€“ which is historically correct; Elon Musk joined later)\n",
    "# ðŸ” Reversed the last name\n",
    "# âž• Used the calculator to count characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e0db48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find information about the topic 'LangChain'. I can do this by using the `summarize_wikipedia` tool.\n",
      "\n",
      "Action: summarize_wikipedia\n",
      "Action Input: 'LangChain'\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "Page: Milvus (vector database)\n",
      "Summary: Milvus is a distributed vector database developed by Zilliz. It is available as both open-source software and a cloud service.\n",
      "Milvus is an open-source project under LF AI & Data Foundation distributed under the Apache License 2.0.\n",
      "\n",
      "Page: Model Context Protocol\n",
      "Summary: The Model Context Protocol (MCP) is an open standard, open-source framework introduced by Anthropic in November 2024 to standardize the way artificial intelligence (AI) systems like large language models (LLMs) integrate and share data with external tools, systems, and data sources. MCP provides a universal interface for reading files, executing functions, and handling contextual prompts. Following its announcement, the protocol was adopted by major AI providers, including OpenAI and Google DeepMind.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m The question asked for information about LangChain, but the summary provided also includes information about Milvus and the Model Context Protocol (MCP). However, the summary does mention that LangChain is a software framework that helps facilitate the integration of large language models into applications.\n",
      "\n",
      "Final Answer: LangChain is a software framework that helps facilitate the integration of large language models into applications. It is used for tasks such as document analysis, summarization, chatbots, and code analysis.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"Use the summarize_wikipedia tool to summarize the topic 'LangChain'.\",\n",
       " 'output': 'LangChain is a software framework that helps facilitate the integration of large language models into applications. It is used for tasks such as document analysis, summarization, chatbots, and code analysis.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ðŸ”¨ Step 5: Build a Custom Tool â€” Example: Summarize Wikipedia Article\n",
    "from langchain.tools import tool\n",
    "\n",
    "# @tool\n",
    "# def summarize_wikipedia(topic: str) -> str:\n",
    "#     \"\"\"Searches Wikipedia for a topic and summarizes it.\"\"\"\n",
    "#     from langchain.utilities import WikipediaAPIWrapper\n",
    "#     return WikipediaAPIWrapper().run(topic)\n",
    "\n",
    "# Make Tool More Robust\n",
    "# If needed, you can wrap your tool to catch blank pages or disambiguation:\n",
    "@tool\n",
    "def summarize_wikipedia(topic: str) -> str:\n",
    "    \"\"\"Searches and summarizes a topic using Wikipedia.\"\"\"\n",
    "    from langchain.utilities import WikipediaAPIWrapper\n",
    "    wiki = WikipediaAPIWrapper()\n",
    "    summary = wiki.run(topic)\n",
    "    return summary or \"No Wikipedia summary found for that topic.\"\n",
    "\n",
    "\n",
    "# tools list\n",
    "tools = [\n",
    "    WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper()),\n",
    "    PythonREPLTool(name=\"Calculator\", description=\"Useful for math or conversions.\"),\n",
    "    reverse_tool,  # your custom reverse tool\n",
    "    summarize_wikipedia  # âœ… NEW summary tool\n",
    "]\n",
    "\n",
    "# ðŸ” Add memory to your agent\n",
    "agent_with_memory = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True  # âœ… this avoids crashes on invalid formats\n",
    ")\n",
    "\n",
    "# test\n",
    "# agent_with_memory.invoke(\"Summarize the Wikipedia article on LangChain.\") #error model got confused and code broke\n",
    "agent_with_memory.invoke(\"Use the summarize_wikipedia tool to summarize the topic 'LangChain'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdf8545",
   "metadata": {},
   "source": [
    "Why? Because now you're nudging the LLM to:\n",
    "\n",
    "Thought: I should use the summarize_wikipedia tool.\n",
    "Action: summarize_wikipedia\n",
    "Action Input: LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c4ff6a",
   "metadata": {},
   "source": [
    "# ðŸ”§ Step 6: PDF Summarizer Tool\n",
    "Weâ€™ll add a summarize_pdf tool so your agent can summarize uploaded PDF content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf5b251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m To summarize the content of a PDF file, I need to use the `summarize_pdf` tool.\n",
      "\n",
      "Action: summarize_pdf\n",
      "Action Input: company_report.pdf\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m Rakshath U Shetty is a Computer Science graduate from Dayananda Sagar University in Bengaluru, India, with a CGPA of 9.31 and expected graduation in May 2024. She has gained experience as a Software Engineer Intern and Junior Data Engineer at various startups, including Freo - MoneyTap and AnTech Crew.\n",
      "\n",
      "At Freo - MoneyTap, Rakshath developed and debugged code, automated testing, and improved the repayments service, leading to significant efficiency and accuracy gains. At AnTech Crew, she led a team, secured 65+ clients, and engineered several projects, including a robust backend project for TaskFlow and a MERN Stack application.\n",
      "\n",
      "Rakshath has also worked on various projects, such as CastX, a multimedia engagement platform, UR-Connect, a social media platform to enhance productivity, and Autocapture of Selfie, a machine learning project. She has showcased her work on Github and LinkedIn. Her current contact information is provided.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Final Answer: Rakshath U Shetty is a Computer Science graduate with a CGPA of 9.31, expected to graduate in May 2024. She has worked as a Software Engineer Intern and Junior Data Engineer at various startups, including Freo - MoneyTap and AnTech Crew. At Freo, she developed and debugged code, automated testing, and improved the repayments service. At AnTech Crew, she led a team, secured 65+ clients, and engineered several projects. Rakshath has also worked on various projects such as CastX, UR-Connect, Autocapture of Selfie, and has showcased her work on Github and LinkedIn. Her current contact information is provided.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'summarize_pdf company_report.pdf',\n",
       " 'output': 'Rakshath U Shetty is a Computer Science graduate with a CGPA of 9.31, expected to graduate in May 2024. She has worked as a Software Engineer Intern and Junior Data Engineer at various startups, including Freo - MoneyTap and AnTech Crew. At Freo, she developed and debugged code, automated testing, and improved the repayments service. At AnTech Crew, she led a team, secured 65+ clients, and engineered several projects. Rakshath has also worked on various projects such as CastX, UR-Connect, Autocapture of Selfie, and has showcased her work on Github and LinkedIn. Her current contact information is provided.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# âœ… 1. Create the PDF Summary Tool\n",
    "# You already have PyMuPDF (via fitz) in your app, so reuse it:\n",
    "from langchain.tools import tool\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "@tool\n",
    "def summarize_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"Extracts and summarizes text from a PDF file at the given path.\"\"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        full_text = \"\"\n",
    "        for page in doc:\n",
    "            full_text += page.get_text()\n",
    "        doc.close()\n",
    "\n",
    "        # Optional: Summarize using LLM\n",
    "        from langchain.chat_models import ChatOpenAI\n",
    "        # llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "        summary_prompt = f\"Summarize the following text:\\n\\n{full_text[:3000]}\"  # Avoid long inputs\n",
    "        return llm.predict(summary_prompt)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error reading PDF: {str(e)}\"\n",
    "\n",
    "# âœ… 2. Add it to Your Tools List\n",
    "tools = [\n",
    "    WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper()),\n",
    "    PythonREPLTool(name=\"Calculator\", description=\"Useful for math or conversions.\"),\n",
    "    reverse_tool,\n",
    "    summarize_wikipedia,\n",
    "    summarize_pdf  # âœ… new PDF tool\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True  # âœ… this avoids crashes on invalid formats\n",
    ")\n",
    "\n",
    "# âœ… 3. Test the Agent\n",
    "\n",
    "# agent.invoke(\"Summarize the file at 'company_report.pdf'\")\n",
    "agent.invoke({\"input\": \"summarize_pdf company_report.pdf\"})\n",
    "# Make sure 'docs/company_report.pdf' exists in your local env or Spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7048b798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find the latest news about OpenAI. I will use the tavily_search_results_json search engine for this.\n",
      "\n",
      "Action: tavily_search_results_json\n",
      "Action Input: latest news about OpenAI\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m[{'title': 'News - OpenAI', 'url': 'https://openai.com/news/', 'content': \"How we're responding to The New York Times' data demands in order to protect user privacy SecurityJun 5, 2025 Addendum to OpenAI o3 and o4-mini system card: OpenAI o3 Operator SafetyMay 23, 2025 OpenAI Deutschland CompanyMay 22, 2025 Introducing Stargate UAE Global AffairsMay 22, 2025 New tools and features in the Responses API ProductMay\", 'score': 0.829285}, {'title': 'OpenAI\\'s 5-Stage AI Roadmap, Explained Using the \"3 Levels ... - Medium', 'url': 'https://medium.com/@The_Last_AI/openais-5-stage-ai-roadmap-explained-using-the-3-levels-of-ai-adoption-and-the-6-levels-of-e295693cc105', 'content': \"In July 2024, news sources reported OpenAI internally presented a new 5-stage roadmap of AI development, which is a move away from emphasizing the development of AGI. OpenAI's 5 Stages of AI\", 'score': 0.81770587}, {'title': \"OpenAI says newest AI models o3 and o4-mini can 'think with images' - CNBC\", 'url': 'https://www.cnbc.com/2025/04/16/openai-releases-most-advanced-ai-model-yet-o3-o4-mini-reasoning-images.html', 'content': 'logo\\nlogo\\nJoin IC\\nJoin Pro\\nlogo\\nJoin IC\\nJoin Probackground of header\\nforeground of header\\n\\n# OpenAI says newest AI model can \\'think with images,\\' understanding diagrams and sketches\\n\\nthumbnail\\n\\nOpenAI has released its latest artificial intelligence model, which it said is capable of \"thinking with images,\" meaning it can understand and analyze a user\\'s sketches and diagrams, even if they\\'re low quality. [...] Since introducing its viral ChatGPT chatbot in late 2022, OpenAI has been rapidly upgrading its models to go well beyond text into images, voice and videos. The company is racing to stay ahead in generative AI, where it faces heated competition from rivals including Google, Anthropic and Elon Musk\\'s xAI. [...] The company, valued at $300 billion in a funding round last month, said that o3 and o4-mini are its first AI models that can \"think with images.\" That means \"they don\\'t just see an image, they can integrate visual information directly into the reasoning chain,\" according to OpenAI.\\n\\nLast month, OpenAI released a native image-generation feature that went viral online for its ability to produce Studio Ghibli-style anime images.', 'score': 0.7825466}, {'title': \"OpenAI News | Today's Latest Stories - Reuters\", 'url': 'https://www.reuters.com/technology/openai/', 'content': 'Meta CEO Mark Zuckerberg has hired three OpenAI researchers to join his \"superintelligence\" team, the Wall Street Journal reported on Wednesday,', 'score': 0.7722049}, {'title': 'OpenAI revises AI model release schedule: o3 and o4-mini arriving in ...', 'url': 'https://techstartups.com/2025/04/04/openai-revises-ai-model-release-timeline-o3-and-o4-mini-coming-first-gpt-5-to-follow-in-a-few-months/', 'content': 'OpenAI is switching things up. In a post shared on X, CEO Sam Altman announced that the company will release two new modelsâ€”o3 and o4-mini in the next couple of weeks, with GPT-5 now expected a few months later. \"Change of plans: we are going to release o3 and o4-mini after all, probably in a couple of weeks, and then do GPT-5 in a few months,\" Altman shared on X.', 'score': 0.76847315}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the latest news about OpenAI. The latest news includes the release of OpenAI's newest AI models o3 and o4-mini, which can \"think with images\" and understand diagrams and sketches. OpenAI has been rapidly upgrading its models to go beyond text into images, voice, and videos. The company is also facing competition from rivals such as Google, Anthropic, and Elon Musk's xAI.\n",
      "\n",
      "Final Answer: OpenAI has released its latest artificial intelligence models, o3 and o4-mini, which can \"think with images\" and understand diagrams and sketches. The company is racing to stay ahead in generative AI and faces competition from rivals such as Google, Anthropic, and Elon Musk's xAI.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the latest news about OpenAI?',\n",
       " 'output': 'OpenAI has released its latest artificial intelligence models, o3 and o4-mini, which can \"think with images\" and understand diagrams and sketches. The company is racing to stay ahead in generative AI and faces competition from rivals such as Google, Anthropic, and Elon Musk\\'s xAI.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ðŸ”— Step 6: Add Google Search Tool (Real-Time Web Access)\n",
    "# We'll use Tavily (simpler and free) or SerpAPI (powerful but needs API key). Iâ€™ll guide with Tavily first:\n",
    "\n",
    "# âœ… 1. Install Tavily - pip install -U langchain-tavily\n",
    "\n",
    "# âœ… 2. Get Free API Key - .env\n",
    "\n",
    "# âœ… 3. Add Tavily Search Tool in LangChain\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "\n",
    "api_key=os.getenv(\"TAVILY_API_KEY\")\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search_tool = TavilySearchResults(k=5)\n",
    "\n",
    "# âœ… 4. Add to Tools List\n",
    "tools = [\n",
    "    WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper()),\n",
    "    PythonREPLTool(name=\"Calculator\", description=\"Useful for math or conversions.\"),\n",
    "    reverse_tool,\n",
    "    summarize_wikipedia,\n",
    "    summarize_pdf,\n",
    "    search_tool  # âœ… Google-style web search\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True  # âœ… this avoids crashes on invalid formats\n",
    ")\n",
    "\n",
    "# âœ… 5. Test It\n",
    "agent.invoke(\"What is the latest news about OpenAI?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a818d5",
   "metadata": {},
   "source": [
    "Tavily Search/ âœ… is working perfectly now! - Alternative SERP API\n",
    "\n",
    "- You just ran a live query for \"latest news about OpenAI\", and the agent successfully:\n",
    "\n",
    "- Queried Tavilyâ€™s real-time web search,\n",
    "\n",
    "- Retrieved articles (from CNBC, Reuters, Medium, etc.),\n",
    "\n",
    "- Summarized the updates clearly (about o3, o4-mini, GPT-5, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a952b3",
   "metadata": {},
   "source": [
    "ðŸ”—ðŸ§  Next Step: Multi-Tool RAG Agents\n",
    "Now weâ€™ll:\n",
    "\n",
    "- Combine PDF + Calculator + Web Search into one intelligent agent,\n",
    "- Let it decide which tool to use based on your query,\n",
    "- Add memory, so it remembers facts like:\n",
    "â€œWhat did the user say about Rakshath earlier?â€\n",
    "\n",
    "Shall we begin setting up your Tool-Using Agent with Memory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "096dfc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out what information I have provided about Rakshath earlier. I will use the summarize_wikipedia action to search for Rakshath on Wikipedia.\n",
      "\n",
      "Action: summarize_wikipedia\n",
      "Action Input: Rakshath\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mNo good Wikipedia Search Result was found\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m It seems there is no specific information about a person, place, or topic named \"Rakshath\" on Wikipedia. I'm unable to provide the details you're asking for. I apologize for any inconvenience.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m Thought: I need to search for any previous interactions or mentions of \"Rakshath\" in the conversation. I will use the tavily_search_results_json action to search for \"Rakshath\" in the conversation history.\n",
      "\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"Rakshath\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{'title': 'Rakshath - Hindu Boy Name Meaning and Pronunciation', 'url': 'https://www.ask-oracle.com/baby-name/rakshath/', 'content': \"Rakshath is a name of Sanskrit origin, meaning 'protected' or 'defended.' It is used predominantly in India and within Indian communities. Rakshath is traditionally a masculine name and is often associated with strength and protection, reflecting the values of guardianship and safety. [...] Online Psychic Reading Â»\\n\\n# Rakshath - Hindu Boy Name Meaning and Pronunciation\\n\\n## Rakshath\\n\\nRakshath is a name of Sanskrit origin, meaning 'protected' or 'defended.' It is used predominantly in India and within Indian communities. Rakshath is traditionally a masculine name and is often associated with strength and protection, reflecting the values of guardianship and safety. [...] This name captures a powerful essence and is valued for its connotations of safeguarding and vigilance. It is straightforward to write and pronounce, contributing to its popularity among parents choosing names that embody strength and security.\\n\\nIn terms of cultural relevance, Rakshath resonates within Hindu faith and philosophy, symbolizing the protective aspects of divinity. While not overly common in popular culture, it occasionally appears in stories and folklore.\", 'score': 0.92359936}, {'title': 'Rakshath Name Meaning: Its Powerful Symbolism, Destiny and Luck', 'url': 'https://nameecho.com/rakshath', 'content': \"Red CoralThe Red Coral is the favorable gemstone for people whose name is Rakshath. This is a gem that invokes the strength to stand one's ground and not drift away in idealism. Red Coral encourages one to be open about the opportunities that surface in their life.\\n\\nRed Coral\\n\\nAnimal Spirit: Giraffe [...] Name Echo\\nName Echo\\nName Echo\\nEida Goodman\\n\\n# Rakshath Name Meaning: Its Powerful Symbolism, Destiny and Luck\\n\\nThe name Rakshath invokes warmth, inquisitiveness and poise.\\n\\n## Letter Analysis [...] Life Lesson & Challenge: In the case of the name Rakshath, since the first vowel is 'A', the life lesson relates to this person acknowledging that, in time, they will not be as strong as they used to, whilst the life challenge refers to stopping themselves from letting others use their creativity.\\n\\nSpirituality Charge: Remarkable\\n\\n## Name Numerology\\n\\nRakshath Name Numerology: 5\", 'score': 0.79369855}, {'title': 'Rakshat, Raká¹£at: 1 definition', 'url': 'https://www.wisdomlib.org/definition/rakshat', 'content': 'Sanskrit, also spelled à¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤®à¥ (saá¹ƒská¹›tam), is an ancient language of India commonly seen as the grandmother of the Indo-European language family (even English!). Closely allied with Prakrit and Pali, Sanskrit is more exhaustive in both grammar and terms and has the most extensive collection of literature in the world, greatly surpassing its sister-languages Greek and Latin.\\n\\nDiscover the meaning of rakshat or raksat in the context of Sanskrit from the community on Patreon [...] The Sanskrit term Raká¹£at can be transliterated into English as Raksat or Rakshat, using the IAST transliteration scheme (?) \"IAST stands for International Alphabet of Sanskrit Transliteration\").\\n\\n## Languages of India and abroad\\n\\n### Sanskrit dictionary\\n\\nRaká¹£at (à¤°à¤•à¥à¤·à¤¤à¥).â€”mfn. (-ká¹£an-ká¹£antÄ«-ká¹£at) Preserving, guarding, protecting. E. raká¹£ to preserve, Å›atá¹› aff.', 'score': 0.767638}, {'title': 'Rakshath Name Meaning & Origins, Nicknames, Sibling Ideas', 'url': 'https://namesabout.com/Rakshath-meaning/', 'content': 'The name Rakshath carries a unique charm with each letter symbolizing something special. Breaking it down alphabetically reveals its deeper meaning and essence, making it a name full of personality and significance.', 'score': 0.72489023}, {'title': 'Rakshat - Name Meaning â€” Is Your Name Helping You?', 'url': 'https://www.kabalarians.com/name-meanings/male/Rakshat.htm', 'content': 'Rakshat - Detailed Meaning. Your name of Rakshat has made you good-natured, friendly, and kind. As diplomacy is one of your strong points, people like you at', 'score': 0.63098115}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I found several search results about the meaning and origin of the name \"Rakshath.\" Here's a summary of the information:\n",
      "\n",
      "Rakshath is a name of Sanskrit origin, meaning 'protected' or 'defended.' It is used predominantly in India and within Indian communities. Rakshath is traditionally a masculine name and is often associated with strength and protection, reflecting the values of guardianship and safety. This name captures a powerful essence and is valued for its connotations of safeguarding and vigilance.\n",
      "\n",
      "The name Rakshath invokes warmth, inquisitiveness, and poise. In terms of cultural relevance, Rakshath resonates within Hindu faith and philosophy, symbolizing the protective aspects of divinity.\n",
      "\n",
      "Rakshath is also associated with the gemstone Red Coral, which encourages one to be open about the opportunities that surface in their life. The name Rakshath has a remarkable spirituality charge.\n",
      "\n",
      "Thought: I now know the final answer\n",
      "Final Answer: The name Rakshath is of Sanskrit origin, meaning 'protected' or 'defended.' It is traditionally a masculine name and is often associated with strength and protection, reflecting the values of guardianship and safety. The name Rakshath invokes warmth, inquisitiveness, and poise, and it resonates within Hindu faith and philosophy, symbolizing the protective aspects of divinity. It is also associated with the gemstone Red Coral.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What did I say earlier about Rakshath?',\n",
       " 'chat_history': [HumanMessage(content='What did I say earlier about Rakshath?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"The name Rakshath is of Sanskrit origin, meaning 'protected' or 'defended.' It is traditionally a masculine name and is often associated with strength and protection, reflecting the values of guardianship and safety. The name Rakshath invokes warmth, inquisitiveness, and poise, and it resonates within Hindu faith and philosophy, symbolizing the protective aspects of divinity. It is also associated with the gemstone Red Coral.\", additional_kwargs={}, response_metadata={})],\n",
       " 'output': \"The name Rakshath is of Sanskrit origin, meaning 'protected' or 'defended.' It is traditionally a masculine name and is often associated with strength and protection, reflecting the values of guardianship and safety. The name Rakshath invokes warmth, inquisitiveness, and poise, and it resonates within Hindu faith and philosophy, symbolizing the protective aspects of divinity. It is also associated with the gemstone Red Coral.\"}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multi-Tool Agent with Memory â€” the real Research Assistant! ðŸ”—ðŸ§ \n",
    "# 1. Import Requirements\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.tools import Tool\n",
    "\n",
    "# âœ… Tools you've already created\n",
    "from langchain.tools.tavily_search import TavilySearchResults\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool # LangChain already provides a simple Python REPL tool that lets the agent do math.\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "\n",
    "api_key=os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "# âœ… Your custom tools\n",
    "tools = [\n",
    "    TavilySearchResults(max_results=5),\n",
    "    WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper()),\n",
    "    PythonREPLTool(name=\"Calculator\", description=\"Useful for math or conversions.\"),\n",
    "    reverse_tool,\n",
    "    summarize_pdf,\n",
    "    summarize_wikipedia\n",
    "]\n",
    "\n",
    "# 2. Add Memory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# 3. Initialize Agent with Tools + Memory\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",             # âœ… Mandatory\n",
    "    \"HTTP-Referer\": \"https://github.com/Rakshath66\",  # âœ… Required by OpenRouter\n",
    "    \"X-Title\": \"LangChain Agent\"                      # âœ… Optional, branding\n",
    "}\n",
    "llm = ChatOpenAI(   # âœ… not OpenAI\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    model=\"mistralai/mistral-7b-instruct\",\n",
    "    temperature=0,\n",
    "    default_headers=headers\n",
    ")\n",
    "\n",
    "agent_with_memory = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "# 4. Test It!\n",
    "# agent_with_memory.invoke({\"input\": \"Who is Rakshath U Shetty?\"})\n",
    "agent_with_memory.invoke({\"input\": \"What did I say earlier about Rakshath?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c033eff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49889bef",
   "metadata": {},
   "source": [
    "Great question! Let‚Äôs break it down clearly.\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ What is **FastAPI**?\n",
    "\n",
    "**FastAPI** is a modern, fast (high-performance) web framework for building APIs with Python 3.7+ using:\n",
    "\n",
    "* Standard **Python type hints**\n",
    "* Built-in **data validation** using `pydantic`\n",
    "* Automatic **interactive docs** with Swagger and ReDoc\n",
    "* **Asynchronous** and super fast (based on Starlette + Uvicorn)\n",
    "\n",
    "It‚Äôs perfect for deploying **LLMs**, **RAG systems**, or **tool-based agents** as microservices.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Minimal FastAPI Example\n",
    "\n",
    "Here are the **most important lines** to create an endpoint:\n",
    "\n",
    "```python\n",
    "from fastapi import FastAPI\n",
    "\n",
    "# Step 1: Create app\n",
    "app = FastAPI()\n",
    "\n",
    "# Step 2: Define endpoint\n",
    "@app.get(\"/hello\")\n",
    "def say_hello():\n",
    "    return {\"message\": \"Hello from FastAPI!\"}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ What each line does:\n",
    "\n",
    "| Line                          | Purpose                                  |\n",
    "| ----------------------------- | ---------------------------------------- |\n",
    "| `from fastapi import FastAPI` | Import FastAPI class                     |\n",
    "| `app = FastAPI()`             | Create the FastAPI app instance          |\n",
    "| `@app.get(\"/hello\")`          | Declare a **GET endpoint** at `/hello`   |\n",
    "| `def say_hello():`            | Function to execute when endpoint is hit |\n",
    "| `return {\"message\": \"...\"}`   | Returns JSON response automatically      |\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Common Endpoint Types:\n",
    "\n",
    "* `@app.get(\"/...\")` ‚Üí Fetch data (like health check)\n",
    "* `@app.post(\"/...\")` ‚Üí Send data (like uploading file or asking question)\n",
    "* `@app.put(\"/...\")` ‚Üí Update data\n",
    "* `@app.delete(\"/...\")` ‚Üí Delete data\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Test It:\n",
    "\n",
    "Run locally with:\n",
    "\n",
    "```bash\n",
    "uvicorn main:app --reload\n",
    "```\n",
    "\n",
    "Visit [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs) to test with Swagger UI!\n",
    "\n",
    "---\n",
    "\n",
    "Next: Want to create an endpoint that accepts a **question string** and returns a dummy LLM answer?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03a0952",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6348af8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting fastapi\n",
      "  Downloading fastapi-0.116.0-py3-none-any.whl (95 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95 kB 739 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting uvicorn\n",
      "  Downloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting starlette<0.47.0,>=0.40.0\n",
      "  Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 72 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.8.0 in /Users/rakshathushetty/Library/Python/3.9/lib/python/site-packages (from fastapi) (4.14.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /Users/rakshathushetty/Library/Python/3.9/lib/python/site-packages (from fastapi) (2.11.7)\n",
      "Requirement already satisfied: click>=7.0 in /Users/rakshathushetty/Library/Python/3.9/lib/python/site-packages (from uvicorn) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/rakshathushetty/Library/Python/3.9/lib/python/site-packages (from uvicorn) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rakshathushetty/Library/Python/3.9/lib/python/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/rakshathushetty/Library/Python/3.9/lib/python/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/rakshathushetty/Library/Python/3.9/lib/python/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /Users/rakshathushetty/Library/Python/3.9/lib/python/site-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/rakshathushetty/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/rakshathushetty/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/rakshathushetty/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
      "Installing collected packages: starlette, uvicorn, fastapi\n",
      "Successfully installed fastapi-0.116.0 starlette-0.46.2 uvicorn-0.35.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fastapi uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467c4b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, Request\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# 1. Create app instance\n",
    "app = FastAPI()\n",
    "\n",
    "# 2. Define request schema using Pydantic\n",
    "class AskRequest(BaseModel):\n",
    "    question: str\n",
    "\n",
    "# 3. Define /ask POST endpoint\n",
    "@app.post(\"/ask\")\n",
    "def ask_question(req: AskRequest):\n",
    "    # For now, return a dummy LLM-style response\n",
    "    answer = f\"You asked: '{req.question}'. Here's a dummy answer from your LLM.\"\n",
    "    return {\"answer\": answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84121d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m:     Will watch for changes in these directories: ['/Users/rakshathushetty/Desktop/ai/ai-foundations/phase3']\n",
      "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://127.0.0.1:8000\u001b[0m (Press CTRL+C to quit)\n",
      "\u001b[32mINFO\u001b[0m:     Started reloader process [\u001b[36m\u001b[1m53225\u001b[0m] using \u001b[36m\u001b[1mStatReload\u001b[0m\n",
      "/Users/rakshathushetty/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "\u001b[31mERROR\u001b[0m:    Error loading ASGI app. Attribute \"app\" not found in module \"main\".\n",
      "^C\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6397310c",
   "metadata": {},
   "source": [
    "This is a **complete FastAPI-based RAG backend** ‚Äî great job! Let me now explain **every line** step-by-step so you understand how this PDF Q\\&A backend works:\n",
    "\n",
    "---\n",
    "\n",
    "## üß± `FastAPI` App (API layer)\n",
    "\n",
    "```python\n",
    "from fastapi import FastAPI, UploadFile, File, Form\n",
    "```\n",
    "\n",
    "* Imports necessary FastAPI classes for defining routes and handling file/form data.\n",
    "\n",
    "```python\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "```\n",
    "\n",
    "* Adds support for CORS so your frontend (like Streamlit or React) can access the API.\n",
    "\n",
    "```python\n",
    "from rag_pipeline import answer_query, ingest_pdf\n",
    "```\n",
    "\n",
    "* You‚Äôre importing core logic (`answer_query` and `ingest_pdf`) from another file ‚Äî **separating logic from API = good design**.\n",
    "\n",
    "```python\n",
    "import shutil\n",
    "```\n",
    "\n",
    "* Used to copy the uploaded PDF into a local directory.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ FastAPI App + CORS Setup\n",
    "\n",
    "```python\n",
    "app = FastAPI()\n",
    "```\n",
    "\n",
    "* Instantiates the API application.\n",
    "\n",
    "```python\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # Allow all origins (you can restrict this)\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "```\n",
    "\n",
    "* Adds middleware to allow any frontend (like Streamlit app on another port) to call these endpoints.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç `/health` Endpoint\n",
    "\n",
    "```python\n",
    "@app.get(\"/health\")\n",
    "def health():\n",
    "    return {\"status\": \"ok\"}\n",
    "```\n",
    "\n",
    "* Simple **health check** endpoint to verify the server is running.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† `/ask` Endpoint ‚Äî Accepts a query\n",
    "\n",
    "```python\n",
    "@app.post(\"/ask\")\n",
    "def ask_question(query: str = Form(...)):\n",
    "    answer = answer_query(query)\n",
    "    return {\"answer\": answer}\n",
    "```\n",
    "\n",
    "* Accepts a **form field named `query`** (not JSON).\n",
    "* Calls `answer_query(query)` which uses FAISS to find matching PDF chunks and return a pseudo-answer.\n",
    "\n",
    "---\n",
    "\n",
    "### üìÑ `/upload_pdf` ‚Äî Upload + index PDF\n",
    "\n",
    "```python\n",
    "@app.post(\"/upload_pdf\")\n",
    "def upload(file: UploadFile = File(...)):\n",
    "    with open(f\"data/{file.filename}\", \"wb\") as buffer:\n",
    "        shutil.copyfileobj(file.file, buffer)\n",
    "    ingest_pdf(f\"data/{file.filename}\")\n",
    "    return {\"status\": \"PDF uploaded and indexed\"}\n",
    "```\n",
    "\n",
    "* Accepts a PDF file via `multipart/form-data`.\n",
    "* Saves it to `data/` folder.\n",
    "* Calls `ingest_pdf()` to process + store in memory.\n",
    "\n",
    "---\n",
    "\n",
    "## üîß `rag_pipeline.py` Logic\n",
    "\n",
    "```python\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "```\n",
    "\n",
    "* Libraries to:\n",
    "\n",
    "  * Load SentenceTransformer for embeddings\n",
    "  * Use FAISS for vector search\n",
    "  * Read PDF text\n",
    "\n",
    "---\n",
    "\n",
    "### üì¶ Global Variables\n",
    "\n",
    "```python\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "docs, embeddings, index = [], [], None\n",
    "```\n",
    "\n",
    "* Loads a lightweight embedding model.\n",
    "* Stores PDF chunks, their embeddings, and FAISS index **globally**.\n",
    "\n",
    "---\n",
    "\n",
    "### üìÑ Ingest PDF + Create FAISS Index\n",
    "\n",
    "```python\n",
    "def ingest_pdf(pdf_path):\n",
    "    global docs, embeddings, index\n",
    "```\n",
    "\n",
    "* We modify global variables here.\n",
    "\n",
    "```python\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as f:\n",
    "        reader = PdfReader(f)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "```\n",
    "\n",
    "* Reads and extracts raw text from each page.\n",
    "\n",
    "```python\n",
    "    chunks = text.split(\"\\n\")\n",
    "    docs = chunks\n",
    "    embeddings = model.encode(chunks)\n",
    "    index = faiss.IndexFlatL2(len(embeddings[0]))\n",
    "    index.add(embeddings)\n",
    "```\n",
    "\n",
    "* Splits into line-wise chunks.\n",
    "* Embeds each line using SentenceTransformer.\n",
    "* Creates a FAISS index and adds all vectors.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Query + RAG-style Answer\n",
    "\n",
    "```python\n",
    "def answer_query(query):\n",
    "    if not index: return \"Please upload a PDF first.\"\n",
    "```\n",
    "\n",
    "* Safety check if PDF isn't uploaded yet.\n",
    "\n",
    "```python\n",
    "    query_emb = model.encode([query])\n",
    "    _, I = index.search(query_emb, k=3)\n",
    "    context = \"\\n\".join([docs[i] for i in I[0]])\n",
    "    return f\"Context:\\n{context}\\n\\nAnswer (approx): {query} (based on context)\"\n",
    "```\n",
    "\n",
    "* Embeds the user query.\n",
    "* Finds top 3 similar chunks using FAISS.\n",
    "* Returns them as the **pseudo-context**.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Summary\n",
    "\n",
    "| Part                | Purpose                                                |\n",
    "| ------------------- | ------------------------------------------------------ |\n",
    "| `/upload_pdf`       | Accepts PDF and builds embedding index                 |\n",
    "| `/ask`              | Accepts user query and returns answer from indexed PDF |\n",
    "| SentenceTransformer | Converts text to vectors                               |\n",
    "| FAISS               | Finds similar text chunks                              |\n",
    "| CORS                | Enables frontend apps to use this backend              |\n",
    "\n",
    "---\n",
    "\n",
    "Want to:\n",
    "\n",
    "* Return **real LLM answer** instead of dummy one?\n",
    "* Accept multiple PDFs?\n",
    "* Save and reload FAISS index later?\n",
    "\n",
    "Let me know and I‚Äôll guide you.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b05373",
   "metadata": {},
   "source": [
    "Excellent ‚Äî you're combining **FastAPI** with a **custom RAG pipeline** using `SentenceTransformer` + `FAISS` + `PyPDF2`. Here's a full explanation and cleanup for your two-part code (`app.py` and `rag_pipeline.py`) and why each line matters:\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ `app.py` ‚Äì FastAPI Server\n",
    "\n",
    "```python\n",
    "from fastapi import FastAPI, UploadFile, File, Form\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from rag_pipeline import answer_query, ingest_pdf\n",
    "import shutil\n",
    "```\n",
    "\n",
    "* Imports FastAPI modules and your custom RAG logic.\n",
    "* `shutil` is used to save the uploaded PDF file locally.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "app = FastAPI()\n",
    "```\n",
    "\n",
    "* Creates the FastAPI app instance.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "# Enable CORS (important for connecting from Streamlit frontend)\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # You can restrict this to your frontend domain\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "```\n",
    "\n",
    "* Adds CORS middleware to allow frontend ‚Üí backend interaction.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "@app.get(\"/health\")\n",
    "def health():\n",
    "    return {\"status\": \"ok\"}\n",
    "```\n",
    "\n",
    "* Health check route to verify API is live.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "@app.post(\"/ask\")\n",
    "def ask_question(query: str = Form(...)):\n",
    "    answer = answer_query(query)\n",
    "    return {\"answer\": answer}\n",
    "```\n",
    "\n",
    "* Accepts a question as form input and calls `answer_query` (RAG-style) to fetch the answer using FAISS similarity.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "@app.post(\"/upload_pdf\")\n",
    "def upload(file: UploadFile = File(...)):\n",
    "    with open(f\"data/{file.filename}\", \"wb\") as buffer:\n",
    "        shutil.copyfileobj(file.file, buffer)\n",
    "    ingest_pdf(f\"data/{file.filename}\")\n",
    "    return {\"status\": \"PDF uploaded and indexed\"}\n",
    "```\n",
    "\n",
    "* Accepts PDF upload, saves it to `data/`, then processes it for embeddings via `ingest_pdf()`.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ `rag_pipeline.py` ‚Äì Custom RAG Logic\n",
    "\n",
    "```python\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "```\n",
    "\n",
    "* Uses:\n",
    "\n",
    "  * `SentenceTransformer` to embed text\n",
    "  * `FAISS` for fast similarity search\n",
    "  * `PyPDF2` to read PDFs\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "```\n",
    "\n",
    "* Loads a lightweight sentence embedding model (great for Q\\&A, semantic search).\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "docs, embeddings, index = [], [], None\n",
    "```\n",
    "\n",
    "* Global state to store document chunks, their embeddings, and the FAISS index.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "def ingest_pdf(pdf_path):\n",
    "    global docs, embeddings, index\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as f:\n",
    "        reader = PdfReader(f)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "\n",
    "    chunks = text.split(\"\\n\")  # Basic chunking, could improve with better chunk logic\n",
    "    docs = chunks\n",
    "    embeddings = model.encode(chunks)\n",
    "    index = faiss.IndexFlatL2(len(embeddings[0]))\n",
    "    index.add(embeddings)\n",
    "```\n",
    "\n",
    "* Reads all text from the PDF, splits into lines/chunks, encodes each chunk, then builds a FAISS index on embeddings.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "def answer_query(query):\n",
    "    if not index: return \"Please upload a PDF first.\"\n",
    "    query_emb = model.encode([query])\n",
    "    _, I = index.search(query_emb, k=3)\n",
    "    context = \"\\n\".join([docs[i] for i in I[0]])\n",
    "    return f\"Context:\\n{context}\\n\\nAnswer (approx): {query} (based on context)\"\n",
    "```\n",
    "\n",
    "* Encodes the question, finds top-3 similar chunks via FAISS, returns those as context.\n",
    "* The ‚Äúanswer‚Äù is not generated ‚Äî it's simulated. You can add GPT-style summarization later.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Next Steps\n",
    "\n",
    "You now have:\n",
    "‚úÖ File upload\n",
    "‚úÖ Ingestion pipeline\n",
    "‚úÖ Semantic search\n",
    "‚úÖ FastAPI backend\n",
    "\n",
    "‚úÖ You can now:\n",
    "\n",
    "* Connect your **Streamlit frontend** to `/upload_pdf` and `/ask`\n",
    "* Extend `answer_query()` to call OpenAI/Claude with `context + question` for real answers.\n",
    "\n",
    "Want me to show how to connect this to Streamlit now?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314702e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
